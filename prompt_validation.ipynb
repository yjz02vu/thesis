{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e61045a-0a08-4b78-9c54-1e58969038bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py (from rouge-score)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in /home/ziggy/anaconda3/lib/python3.11/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/ziggy/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ziggy/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/ziggy/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /home/ziggy/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (4.65.0)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=f7294e487ac02fc65e31855f1bb59133d8189a4aba78695fe2f6f15e1189adb9\n",
      "  Stored in directory: /home/ziggy/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.1.0 rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9274cec6-72d8-4c45-9d60-1c91befd6d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartModel\n",
    "import torch\n",
    "\n",
    "import json\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a89b33-b08b-489b-a834-20a7159fbe37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ziggy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8371e-7a11-47e9-8297-3fe8a1f46443",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535d025-9000-427b-b2e3-52c16ce07993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of questions\n",
    "ref_ls = [\n",
    "        \"The cat is on the mat\",\n",
    "        \"There is a cat on the mat\"\n",
    "    ]\n",
    "cad_ls = [\n",
    "        \"The cat is on the mat\",\n",
    "        \"There is not any cat on the mat\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e942b977-9cd0-44d5-b5e2-bdca2857aed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziggy/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to compute BARTScore\n",
    "def compute_bart_score(candidates, references):\n",
    "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "    model = BartModel.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "    candidate_ids = [tokenizer.encode(cand, return_tensors='pt') for cand in candidates]\n",
    "    reference_ids = [tokenizer.encode(ref[0], return_tensors='pt') for ref in references]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = []\n",
    "        for cand_id, ref_id in zip(candidate_ids, reference_ids):\n",
    "            outputs = model(input_ids=cand_id, labels=ref_id)\n",
    "            score = outputs.loss.item()\n",
    "            scores.append(score)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Compute and print scores\n",
    "bleu_score = compute_bleu(candidates, references)\n",
    "# rouge_scores = compute_rouge(candidates, references)\n",
    "# bart_scores = compute_bart_score(candidates, references)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "# print(\"ROUGE Scores:\", rouge_scores)\n",
    "# print(\"BART Scores:\", bart_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26be4c-954e-4859-9def-2730bd1d049d",
   "metadata": {},
   "source": [
    "## calculate bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53f53a7-d707-4e80-b532-44df30b6fd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_bleu(reference_texts, hypothesis_texts, ngram_order=4, smoothing=True):\n",
    "    \"\"\"\n",
    "    Calculate BLEU score for a list of reference and hypothesis texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - reference_texts: List of reference texts.\n",
    "    - hypothesis_texts: List of hypothesis texts.\n",
    "    - ngram_order: Maximum n-gram order to use for BLEU calculation.\n",
    "    - smoothing: Whether to apply smoothing.\n",
    "    \n",
    "    Returns:\n",
    "    - bleu_score: The calculated BLEU score.\n",
    "    \"\"\"\n",
    "    smooth_fn = SmoothingFunction().method1 if smoothing else None\n",
    "    weights = tuple((1.0 / ngram_order) for _ in range(ngram_order))\n",
    "    \n",
    "    total_bleu_score = 0.0\n",
    "    for ref, hyp in zip(reference_texts, hypothesis_texts):\n",
    "        ref_tokens = [ref.split()]\n",
    "        hyp_tokens = hyp.split()\n",
    "        bleu_score = sentence_bleu(ref_tokens, hyp_tokens, weights=weights, smoothing_function=smooth_fn)\n",
    "        total_bleu_score += bleu_score\n",
    "    \n",
    "    return total_bleu_score / len(hypothesis_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465c75ae-cf44-4c25-a65c-9fd1ba42867d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score without smoothing: 0.7055668084502599\n",
      "BLEU score with smoothing: 0.7055668084502599\n",
      "BLEU score with lower n-gram order: 0.8273268353539885\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Calculate BLEU score without smoothing\n",
    "bleu_score_no_smoothing = calculate_bleu(ref_ls, cad_ls, ngram_order=4, smoothing=False)\n",
    "print(f\"BLEU score without smoothing: {bleu_score_no_smoothing}\")\n",
    "    \n",
    "# Calculate BLEU score with smoothing\n",
    "bleu_score_with_smoothing = calculate_bleu(ref_ls, cad_ls, ngram_order=4, smoothing=True)\n",
    "print(f\"BLEU score with smoothing: {bleu_score_with_smoothing}\")\n",
    "    \n",
    "# Calculate BLEU score with lower n-gram order\n",
    "bleu_score_lower_ngram = calculate_bleu(ref_ls, cad_ls, ngram_order=2, smoothing=True)\n",
    "print(f\"BLEU score with lower n-gram order: {bleu_score_lower_ngram}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e12d5f-e169-43a0-a727-256f05c74b49",
   "metadata": {},
   "source": [
    "## calculate rough score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7e868a4-808b-4e61-a134-6cd18bc895cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_rouge_per(candidates, references):\n",
    "    \"\"\"\n",
    "    calculate rouge score of each sentence in the candidates list\n",
    "    \n",
    "    Parameters:\n",
    "    - candidates: candidate sentence list\n",
    "    - references: reference sentence list\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = [scorer.score(cand, ref) for cand, ref in zip(candidates, references)]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fad877bf-3e95-4c05-8aea-a415c700ffef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Sentence:\n",
      "[{'rouge1': Score(precision=0.9230769230769231, recall=0.8571428571428571, fmeasure=0.888888888888889), 'rouge2': Score(precision=0.8333333333333334, recall=0.7692307692307693, fmeasure=0.8), 'rougeL': Score(precision=0.9230769230769231, recall=0.8571428571428571, fmeasure=0.888888888888889)}]\n"
     ]
    }
   ],
   "source": [
    "# concatenate every string yo compute \n",
    "def cal_rouge_str(candidates, references):\n",
    "    \"\"\"\n",
    "    calculate rouge score of the sentences in the candidates list in the form of a string\n",
    "    \n",
    "    Parameters:\n",
    "    - candidates: candidate sentence list\n",
    "    - references: reference sentence list\n",
    "    \"\"\"\n",
    "    comb_candi = \"\"\n",
    "    for i in candidates:\n",
    "        comb_candi += i + \" \" \n",
    "    \n",
    "    comb_ref = \"\"\n",
    "    for n in references:\n",
    "        comb_ref += n + \" \" \n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = [scorer.score(comb_candi, comb_ref)]\n",
    "    return scores\n",
    "\n",
    "ref_ls = [\n",
    "        \"The cat is on the mat\",\n",
    "        \"There is a cat on the mat\"\n",
    "    ]\n",
    "cad_ls = [\n",
    "        \"The cat is on the mat\",\n",
    "        \"There is not any cat on the mat\"\n",
    "    ]\n",
    "\n",
    "score = cal_rouge_str(cad_ls, ref_ls)\n",
    "print(\"Concatenated Sentence:\")\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5a92003-a600-4e72-90fa-69e45ca3f806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}, {'rouge1': Score(precision=0.8571428571428571, recall=0.75, fmeasure=0.7999999999999999), 'rouge2': Score(precision=0.6666666666666666, recall=0.5714285714285714, fmeasure=0.6153846153846153), 'rougeL': Score(precision=0.8571428571428571, recall=0.75, fmeasure=0.7999999999999999)}]\n"
     ]
    }
   ],
   "source": [
    "ref_ls = [\n",
    "        \"The cat is on the mat\",\n",
    "        \"There is a cat on the mat\"\n",
    "    ]\n",
    "cad_ls = [\n",
    "        \"The cat is on the mat\",\n",
    "        \"There is not any cat on the mat\"\n",
    "    ]\n",
    "\n",
    "rough_score = cal_rouge_per(cad_ls, ref_ls)\n",
    "print(rough_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "124a9a27-2a76-4dfc-b362-b164ce9b51af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ROUGE Scores: {'rouge1': 0.8999999999999999, 'rouge2': 0.8076923076923077, 'rougeL': 0.8999999999999999}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "def cal_rouge_average(references, candidates):\n",
    "    \"\"\"\n",
    "    calculate average rouge score (f-measure) of sentences in the candidate list\n",
    "    \"\"\"\n",
    "    # Initialize the ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Initialize lists to store scores for each pair\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    # Calculate ROUGE scores for each sentence pair\n",
    "    for ref, cand in zip(references, candidates):\n",
    "        scores = scorer.score(ref, cand)\n",
    "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    avg_rouge1 = np.mean(rouge1_scores)\n",
    "    avg_rouge2 = np.mean(rouge2_scores)\n",
    "    avg_rougeL = np.mean(rougeL_scores)\n",
    "    \n",
    "    return {\n",
    "        'rouge1': avg_rouge1,\n",
    "        'rouge2': avg_rouge2,\n",
    "        'rougeL': avg_rougeL\n",
    "    }\n",
    "\n",
    "\n",
    "overall_scores = calculate_rouge_scores(ref_ls, cad_ls)\n",
    "print(\"Overall ROUGE Scores:\", overall_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea0c3ed5-c270-49c7-8a36-2405f74406cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/c2/d6/ff9baefc8fc679dcd9eb21b29da3ef10c81aa36be630a7ae78e4611588e1/evaluate-0.4.2-py3-none-any.whl.metadata\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (2023.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: packaging in /home/ziggy/anaconda3/lib/python3.11/site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ziggy/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /home/ziggy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86944aad-9fa1-40da-a9e7-82053b227e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ziggy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ziggy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ziggy/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "meteor = evaluate.load('meteor')\n",
    "predictions = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "references = [\"A quick brown fox jumps over the lazy dog.\"]\n",
    "results = meteor.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3945980e-af4e-47e5-b3ce-27099c4b1e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meteor': 0.8993827160493828}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7405aa25-36f4-444e-9a00-409710a354f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8994\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import meteor\n",
    "from nltk import word_tokenize\n",
    "\n",
    "score = round(meteor(\n",
    "       [word_tokenize(\"A quick brown fox jumps over the lazy dog.\")],\n",
    "       word_tokenize('The quick brown fox jumps over the lazy dog.')\n",
    "       ), 4)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d244f4f-913d-40c0-b0ad-18c129111a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288e4328-99de-4940-bedc-75219a282526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate METEOR score\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m meteor_score_value \u001b[38;5;241m=\u001b[39m meteor_score(\n\u001b[1;32m     19\u001b[0m     reference_tokens,\n\u001b[1;32m     20\u001b[0m     candidate_tokens,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# preprocess=preprocess  # Optional: Pass your preprocess function if needed\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETEOR Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeteor_score_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate import meteor_score\n",
    "\n",
    "# Example reference and candidate texts\n",
    "reference_texts = [\"A quick brown fox jumps over the lazy dog.\"]\n",
    "candidate_texts = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "\n",
    "# Tokenize and preprocess (convert to lowercase) the reference and candidate texts\n",
    "reference_tokens = [word_tokenize(text.lower()) for text in reference_texts]\n",
    "candidate_tokens = [word_tokenize(text.lower()) for text in candidate_texts]\n",
    "\n",
    "# Define a preprocess function if needed (e.g., for stemming)\n",
    "def preprocess(tokens):\n",
    "    # Example: Perform any preprocessing (e.g., stemming)\n",
    "    return tokens\n",
    "\n",
    "# Calculate METEOR score\n",
    "meteor_score_value = meteor_score(\n",
    "    reference_tokens,\n",
    "    candidate_tokens,\n",
    "    # preprocess=preprocess  # Optional: Pass your preprocess function if needed\n",
    ")\n",
    "\n",
    "print(f\"METEOR Score: {meteor_score_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add22b57-1c8f-4648-a5be-78b0c8c8964c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m meteor \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is a guide to action which ensures that the military always obeys the commands of the party\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m references \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is a guide to action that ensures that the military will forever heed Party commands\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load('meteor')\n",
    "predictions = [\"It is a guide to action which ensures that the military always obeys the commands of the party\"]\n",
    "references = [\"It is a guide to action that ensures that the military will forever heed Party commands\"]\n",
    "results = meteor.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48557a0-664e-4ab3-b247-8ae9d2803ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']]\n",
      "\n",
      "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "descriptor 'lower' for 'str' objects doesn't apply to a 'list' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(candidate_tokens)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate METEOR score\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m meteor_score_value \u001b[38;5;241m=\u001b[39m meteor_score(reference_tokens, candidate_tokens)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:397\u001b[0m, in \u001b[0;36mmeteor_score\u001b[0;34m(references, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    398\u001b[0m         single_meteor_score(\n\u001b[1;32m    399\u001b[0m             reference,\n\u001b[1;32m    400\u001b[0m             hypothesis,\n\u001b[1;32m    401\u001b[0m             preprocess\u001b[38;5;241m=\u001b[39mpreprocess,\n\u001b[1;32m    402\u001b[0m             stemmer\u001b[38;5;241m=\u001b[39mstemmer,\n\u001b[1;32m    403\u001b[0m             wordnet\u001b[38;5;241m=\u001b[39mwordnet,\n\u001b[1;32m    404\u001b[0m             alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    405\u001b[0m             beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m    406\u001b[0m             gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[1;32m    407\u001b[0m         )\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m reference \u001b[38;5;129;01min\u001b[39;00m references\n\u001b[1;32m    409\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:398\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 398\u001b[0m         single_meteor_score(\n\u001b[1;32m    399\u001b[0m             reference,\n\u001b[1;32m    400\u001b[0m             hypothesis,\n\u001b[1;32m    401\u001b[0m             preprocess\u001b[38;5;241m=\u001b[39mpreprocess,\n\u001b[1;32m    402\u001b[0m             stemmer\u001b[38;5;241m=\u001b[39mstemmer,\n\u001b[1;32m    403\u001b[0m             wordnet\u001b[38;5;241m=\u001b[39mwordnet,\n\u001b[1;32m    404\u001b[0m             alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    405\u001b[0m             beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m    406\u001b[0m             gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[1;32m    407\u001b[0m         )\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m reference \u001b[38;5;129;01min\u001b[39;00m references\n\u001b[1;32m    409\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:326\u001b[0m, in \u001b[0;36msingle_meteor_score\u001b[0;34m(reference, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_meteor_score\u001b[39m(\n\u001b[1;32m    283\u001b[0m     reference: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    284\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    291\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for single hypothesis and reference as per\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"Meteor: An Automatic Metric for MT Evaluation with HighLevels of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     enum_hypothesis, enum_reference \u001b[38;5;241m=\u001b[39m _generate_enums(\n\u001b[1;32m    327\u001b[0m         hypothesis, reference, preprocess\u001b[38;5;241m=\u001b[39mpreprocess\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     translation_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_hypothesis)\n\u001b[1;32m    330\u001b[0m     reference_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_reference)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:42\u001b[0m, in \u001b[0;36m_generate_enums\u001b[0;34m(hypothesis, reference, preprocess)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reference, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects pre-tokenized reference (Iterable[str]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m enum_hypothesis_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mmap\u001b[39m(preprocess, hypothesis)))\n\u001b[1;32m     43\u001b[0m enum_reference_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mmap\u001b[39m(preprocess, reference)))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enum_hypothesis_list, enum_reference_list\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'lower' for 'str' objects doesn't apply to a 'list' object"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Example reference and candidate texts\n",
    "reference_texts = [\"A quick brown fox jumps over the lazy dog.\"]\n",
    "candidate_texts = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "\n",
    "# Tokenize and convert to lowercase\n",
    "reference_tokens = [word_tokenize(text.lower()) for text in reference_texts]\n",
    "candidate_tokens = [word_tokenize(text.lower()) for text in candidate_texts]\n",
    "\n",
    "print(reference_tokens)\n",
    "print()\n",
    "print(candidate_tokens)\n",
    "\n",
    "# Calculate METEOR score\n",
    "meteor_score_value = meteor_score(reference_tokens, candidate_tokens)\n",
    "# print(f\"METEOR Score: {meteor_score_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501e399-023a-4fa9-8b08-d92dbba7fddb",
   "metadata": {},
   "source": [
    "## Meteor Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e99aea3-4585-4f66-9c3a-af326aa0918f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'lower' for 'str' objects doesn't apply to a 'list' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m candidate_tokens \u001b[38;5;241m=\u001b[39m [word_tokenize(text\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m candidate_texts]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate METEOR score\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m meteor_score_value \u001b[38;5;241m=\u001b[39m meteor_score(reference_tokens, candidate_tokens)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETEOR Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeteor_score_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:397\u001b[0m, in \u001b[0;36mmeteor_score\u001b[0;34m(references, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    398\u001b[0m         single_meteor_score(\n\u001b[1;32m    399\u001b[0m             reference,\n\u001b[1;32m    400\u001b[0m             hypothesis,\n\u001b[1;32m    401\u001b[0m             preprocess\u001b[38;5;241m=\u001b[39mpreprocess,\n\u001b[1;32m    402\u001b[0m             stemmer\u001b[38;5;241m=\u001b[39mstemmer,\n\u001b[1;32m    403\u001b[0m             wordnet\u001b[38;5;241m=\u001b[39mwordnet,\n\u001b[1;32m    404\u001b[0m             alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    405\u001b[0m             beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m    406\u001b[0m             gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[1;32m    407\u001b[0m         )\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m reference \u001b[38;5;129;01min\u001b[39;00m references\n\u001b[1;32m    409\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:398\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 398\u001b[0m         single_meteor_score(\n\u001b[1;32m    399\u001b[0m             reference,\n\u001b[1;32m    400\u001b[0m             hypothesis,\n\u001b[1;32m    401\u001b[0m             preprocess\u001b[38;5;241m=\u001b[39mpreprocess,\n\u001b[1;32m    402\u001b[0m             stemmer\u001b[38;5;241m=\u001b[39mstemmer,\n\u001b[1;32m    403\u001b[0m             wordnet\u001b[38;5;241m=\u001b[39mwordnet,\n\u001b[1;32m    404\u001b[0m             alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    405\u001b[0m             beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m    406\u001b[0m             gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[1;32m    407\u001b[0m         )\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m reference \u001b[38;5;129;01min\u001b[39;00m references\n\u001b[1;32m    409\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:326\u001b[0m, in \u001b[0;36msingle_meteor_score\u001b[0;34m(reference, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_meteor_score\u001b[39m(\n\u001b[1;32m    283\u001b[0m     reference: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    284\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    291\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for single hypothesis and reference as per\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"Meteor: An Automatic Metric for MT Evaluation with HighLevels of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     enum_hypothesis, enum_reference \u001b[38;5;241m=\u001b[39m _generate_enums(\n\u001b[1;32m    327\u001b[0m         hypothesis, reference, preprocess\u001b[38;5;241m=\u001b[39mpreprocess\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     translation_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_hypothesis)\n\u001b[1;32m    330\u001b[0m     reference_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_reference)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/translate/meteor_score.py:42\u001b[0m, in \u001b[0;36m_generate_enums\u001b[0;34m(hypothesis, reference, preprocess)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reference, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects pre-tokenized reference (Iterable[str]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m enum_hypothesis_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mmap\u001b[39m(preprocess, hypothesis)))\n\u001b[1;32m     43\u001b[0m enum_reference_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mmap\u001b[39m(preprocess, reference)))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enum_hypothesis_list, enum_reference_list\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'lower' for 'str' objects doesn't apply to a 'list' object"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Example reference and candidate texts\n",
    "reference_texts = [\"A quick brown fox jumps over the lazy dog.\"]\n",
    "candidate_texts = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "\n",
    "# Tokenize the reference and candidate texts into lists of tokens (list of lists)\n",
    "reference_tokens = [word_tokenize(text.lower()) for text in reference_texts]\n",
    "candidate_tokens = [word_tokenize(text.lower()) for text in candidate_texts]\n",
    "\n",
    "# Calculate METEOR score\n",
    "meteor_score_value = meteor_score(reference_tokens, candidate_tokens)\n",
    "print(f\"METEOR Score: {meteor_score_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b31ade-76da-41bb-a1ef-32a44d1054dd",
   "metadata": {},
   "source": [
    "## Calculate Bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc94f163-7251-47a8-a354-37ad9870d4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bart_score(candidates, references):\n",
    "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "    model = BartModel.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "    candidate_ids = [tokenizer.encode(cand, return_tensors='pt') for cand in candidates]\n",
    "    reference_ids = [tokenizer.encode(ref[0], return_tensors='pt') for ref in references]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = []\n",
    "        for cand_id, ref_id in zip(candidate_ids, reference_ids):\n",
    "            outputs = model(input_ids=cand_id, labels=ref_id)\n",
    "            score = outputs.loss.item()\n",
    "            scores.append(score)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2086d25a-22ca-4b91-b70d-11e9e1c56b70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0615b499d485442bb68d2f9f49773596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "BartModel.forward() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m compute_bart_score(cad_ls, ref_ls)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m, in \u001b[0;36mcompute_bart_score\u001b[0;34m(candidates, references)\u001b[0m\n\u001b[1;32m      9\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cand_id, ref_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(candidate_ids, reference_ids):\n\u001b[0;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mcand_id, labels\u001b[38;5;241m=\u001b[39mref_id)\n\u001b[1;32m     12\u001b[0m     score \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: BartModel.forward() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "score = compute_bart_score(cad_ls, ref_ls)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6d91670-abf4-47a9-bbb0-88b64febe8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Obtaining dependency information for bert-score from https://files.pythonhosted.org/packages/c6/8c/bc5457de4c004b1a623b31f7bc8d0375fb699b7d67df11879098b4b7b7c8/bert_score-0.3.13-py3-none-any.whl.metadata\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (2.1.2+cu118)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (2.0.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (4.32.1)\n",
      "Requirement already satisfied: numpy in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (1.24.3)\n",
      "Requirement already satisfied: requests in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: matplotlib in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from bert-score) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from requests->bert-score) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ziggy/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3616a5db-526f-4fb5-80f1-dd522da54ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6705dbded4784b4799dbaf49defd42ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59665d886fa415ca6818dc7a5575a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a939aee816534a12a3481019c3fb3d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79e439b08ad445b8c2b58a8ced29d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out. (read timeout=10.0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    799\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m six\u001b[38;5;241m.\u001b[39mreraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/packages/six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:357\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[1;32m    359\u001b[0m     )\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out. (read timeout=10.0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m reference \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA quick brown fox jumps over a lazy dog.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m candidate \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe quick brown fox jumps over the lazy dog.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m P, R, F1 \u001b[38;5;241m=\u001b[39m score(candidate, reference, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mP\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mR\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bert_score/score.py:98\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m     95\u001b[0m     num_layers \u001b[38;5;241m=\u001b[39m model2layers[model_type]\n\u001b[1;32m     97\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m get_tokenizer(model_type, use_fast_tokenizer)\n\u001b[0;32m---> 98\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(model_type, num_layers, all_layers)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bert_score/utils.py:255\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_type, num_layers, all_layers)\u001b[0m\n\u001b[1;32m    253\u001b[0m     model \u001b[38;5;241m=\u001b[39m T5EncoderModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_type)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_type)\n\u001b[1;32m    256\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:516\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    515\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    517\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:2695\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2683\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   2684\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[1;32m   2694\u001b[0m     }\n\u001b[0;32m-> 2695\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs)\n\u001b[1;32m   2697\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   2699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   2700\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:428\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    429\u001b[0m         path_or_repo_id,\n\u001b[1;32m    430\u001b[0m         filename,\n\u001b[1;32m    431\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    432\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    433\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    434\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    435\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    436\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    437\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    438\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    439\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    440\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[1;32m   1362\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 1364\u001b[0m     http_get(\n\u001b[1;32m   1365\u001b[0m         url_to_download,\n\u001b[1;32m   1366\u001b[0m         temp_file,\n\u001b[1;32m   1367\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1368\u001b[0m         resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1369\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1370\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1371\u001b[0m     )\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:505\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    503\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (resume_size,)\n\u001b[0;32m--> 505\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    506\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    507\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    508\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    510\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    511\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    512\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    513\u001b[0m )\n\u001b[1;32m    514\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m    515\u001b[0m content_length \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:442\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# 3. Exponential backoff\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_backoff(\n\u001b[1;32m    443\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    444\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    445\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    446\u001b[0m     base_wait_time\u001b[38;5;241m=\u001b[39mbase_wait_time,\n\u001b[1;32m    447\u001b[0m     max_wait_time\u001b[38;5;241m=\u001b[39mmax_wait_time,\n\u001b[1;32m    448\u001b[0m     retry_on_exceptions\u001b[38;5;241m=\u001b[39m(ConnectTimeout, ProxyError),\n\u001b[1;32m    449\u001b[0m     retry_on_status_codes\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    450\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    452\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:212\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out. (read timeout=10.0)"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "reference = [\"A quick brown fox jumps over a lazy dog.\"]\n",
    "candidate = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "P, R, F1 = score(candidate, reference, lang=\"en\", verbose=True)\n",
    "print(f\"BERTScore Precision: {P.mean().item()}\")\n",
    "print(f\"BERTScore Recall: {R.mean().item()}\")\n",
    "print(f\"BERTScore F1: {F1.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d56603-2c2a-4459-942d-286f00524f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example BLEU and ROUGE scores for multiple candidate-reference pairs\n",
    "data = {\n",
    "    \"Candidate\": [\"Candidate 1\", \"Candidate 2\", \"Candidate 3\"],\n",
    "    \"BLEU-1\": [0.5, 0.6, 0.7],\n",
    "    \"BLEU-2\": [0.4, 0.5, 0.6],\n",
    "    \"BLEU-4\": [0.3, 0.4, 0.5],\n",
    "    \"ROUGE-1\": [0.6, 0.7, 0.8],\n",
    "    \"ROUGE-2\": [0.5, 0.6, 0.7],\n",
    "    \"ROUGE-L\": [0.55, 0.65, 0.75]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set up the seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot BLEU scores\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Reshape the DataFrame for plotting\n",
    "melted_bleu = df.melt(id_vars=\"Candidate\", value_vars=[\"BLEU-1\", \"BLEU-2\", \"BLEU-4\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Plot BLEU scores with seaborn\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x=\"Candidate\", y=\"Score\", hue=\"Metric\", data=melted_bleu)\n",
    "plt.title('BLEU Scores')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Reshape the DataFrame for plotting\n",
    "melted_rouge = df.melt(id_vars=\"Candidate\", value_vars=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Plot ROUGE scores with seaborn\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x=\"Candidate\", y=\"Score\", hue=\"Metric\", data=melted_rouge)\n",
    "plt.title('ROUGE Scores')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
