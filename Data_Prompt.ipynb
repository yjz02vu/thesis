{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f0a871-12c4-4de7-80e1-d60ec2dd9cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "from data_process import *\n",
    "from s2_data_process_new import *\n",
    "from s3_evaluation import *\n",
    "\n",
    "from tenacity import retry, wait_fixed, stop_after_attempt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key =\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5635fc55-a276-4a17-a082-bceeea34c067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory response_data/raw_conversations/ has been created or already exists.\n",
      "Directory response_data/raw_fq/ has been created or already exists.\n",
      "Directory response_data/prompt/ has been created or already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the directory path\n",
    "dir_conver = 'response_data/raw_conversations/' #for basic conversations\n",
    "dir_fq = 'response_data/raw_fq/' #for following-up questions\n",
    "dir_prompt = 'response_data/prompt/' #for prompt engineering\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(dir_conver, exist_ok=True)\n",
    "os.makedirs(dir_fq, exist_ok=True)\n",
    "os.makedirs(dir_prompt, exist_ok=True)\n",
    "\n",
    "print(f\"Directory {dir_conver} has been created or already exists.\")\n",
    "print(f\"Directory {dir_fq} has been created or already exists.\")\n",
    "print(f\"Directory {dir_prompt} has been created or already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543cd97a-42b8-4db0-a93f-31b619e6f8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load ICF_cate_comb\n",
    "with open(\"predefined_data/icf_cate_comb.json\", 'r', encoding='utf-8') as file:\n",
    "    ICF_cate_comb = json.load(file)\n",
    "    \n",
    "# print(ICF_cate_comb)\n",
    "with open(\"predefined_data/examples.json\", 'r', encoding='utf-8') as efile:\n",
    "    examples = json.load(efile)\n",
    "\n",
    "\n",
    "# print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4adb929-0cca-447f-8b52-e131fdffe74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Changing basic body position', 'Maintaining body position', 'Transferring oneself', 'Lifting and carrying objects', 'Moving objects with lower extremities', 'Fine hand use', 'Hand and arm use', 'Fine foot use', 'Walking', 'Going up and down stairs', 'Moving around', 'Moving around in different locations', 'Moving around using equipment', 'Using transportation', 'Driving', 'Riding animals for transportation'])\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(ICF_cate_comb['mobility'].keys())\n",
    "print(len(list(ICF_cate_comb['mobility'].keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e25636f-684d-4566-9d7b-5593691b7def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Communicating with receiving spoken messages', 'Communicating with receiving nonverbal messages', 'Communicating with receiving formal sign language messages', 'Communicating with receiving written messages', 'Speaking', 'Non-speech vocal expression', 'Singing', 'Producing nonverbal messages', 'Producing messages in formal sign language', 'Writing messages', 'Conversation', 'Discussion', 'Using communication devices and techniques'])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(ICF_cate_comb['communication'].keys())\n",
    "print(len(list(ICF_cate_comb['communication'].keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c646a4fd-12d5-4cfc-a148-be5429c99468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Washing oneself', 'Caring for body parts', 'Toileting', 'Dressing', 'Eating', 'Drinking', \"Looking after one's health\"])\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(ICF_cate_comb['self-care'].keys())\n",
    "print(len(list(ICF_cate_comb['self-care'].keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc9a417",
   "metadata": {},
   "source": [
    "## temperature tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e005ebb-1188-4e1d-aa51-8b93cb5f4259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temperature 1.5 and delete the activity in the user response in prompt\n",
    "@retry(wait=wait_fixed(10), stop=stop_after_attempt(3))\n",
    "def fetch_chat_completion(model, query, num):\n",
    "    \"\"\"\n",
    "    Fetch conversation completions from OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to use for generating completions.\n",
    "    - query: The prompt for the conversation.\n",
    "    - num: number of chat each time\n",
    "    \n",
    "    Returns:\n",
    "    - response_query: The response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    response_query = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=query,\n",
    "        temperature=1.0,\n",
    "        max_tokens=150,\n",
    "        n=num,\n",
    "        request_timeout=60 \n",
    "    )\n",
    "    return response_query\n",
    "\n",
    "def category_converset(function, ICF_cate,  dir_,MODEL=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Generate initial conversations based on ICF definitions and categories.\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_defs: Dictionary of ICF definitions.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - dir: Directory to save the generated conversations.\n",
    "    \"\"\"\n",
    "    data = {f\"{function}\": []}\n",
    "    # function_definition = ICF_defs[function]\n",
    "\n",
    "    for activity, infor in ICF_cate[function].items():\n",
    "        activity_definition = infor[\"definition\"]\n",
    "        count = 0\n",
    "        \n",
    "        if \"examples\" in infor:\n",
    "            examples = infor[\"examples\"]\n",
    "            example_str = f\"The activities can be about {examples}.\"\n",
    "        else:\n",
    "            example_str = \"\"\n",
    "\n",
    "        query = [\n",
    "            {\"role\": \"system\", \"content\": \"You need to play the roles of a care taker (C) and an elderly patient (P)\"},\n",
    "            {\"role\": \"system\", \"content\": \"Generate one small and natural conversation about one activity. This conversation is online. The conversation has around 4 to 6 utterances in total and each utterance should be completed and has less than 20 tokens.\"},\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"The topic of the conversation is about {activity}, which means {activity_definition},{example_str}.\\n\n",
    "             The format is as below,\\n\n",
    "             C: starting conversation  (start the conversation around the activity)\\n\n",
    "             P: utterance (respond naturally)\\n\n",
    "             C: starting conversation  (start the conversation around the activity)\\n\n",
    "             P: utterance (respond naturally)\\n\n",
    "             ...\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"the patients can describe their daily activities and answer questions naturally.\"}\n",
    "        ]\n",
    "\n",
    "        print(f\"gpt-running {function} - {activity}\")\n",
    "\n",
    "        while count <= 30:#change the conversation number needed\n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query, 30)\n",
    "                print(f\"gpt finished {function} - {activity}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity}: {e}\")\n",
    "                continue\n",
    "                \n",
    "            time.sleep(60)  # Wait a minute before retrying\n",
    "                \n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                one_conversation = f'{activity}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "                data[f\"{function}\"].append({\n",
    "                        \"activity\": activity,\n",
    "                        # \"sub_activity\": sub_act,\n",
    "                        \"conversation\": conversation\n",
    "                    })\n",
    "\n",
    "                \n",
    "\n",
    "                count += 1\n",
    "                if count > 30:\n",
    "                    break\n",
    "                    \n",
    "        break\n",
    "                    \n",
    "    \n",
    "    with open(f'{dir_}{function}_noact.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    print(f\"Generated {count} {function} conversations\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return data   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c649ad7d-6bf1-4a27-86b6-0e5aa9540592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-running communication - Communicating with receiving spoken messages\n",
      "gpt finished communication - Communicating with receiving spoken messages\n",
      "gpt finished communication - Communicating with receiving spoken messages\n",
      "Generated 31 communication conversations\n",
      "------------------------------\n",
      "\n",
      "\n",
      "communication-Done\n",
      "\n",
      "gpt-running mobility - Changing basic body position\n",
      "gpt finished mobility - Changing basic body position\n",
      "gpt finished mobility - Changing basic body position\n",
      "Generated 31 mobility conversations\n",
      "------------------------------\n",
      "\n",
      "\n",
      "mobility-Done\n",
      "\n",
      "gpt-running self-care - Washing oneself\n",
      "gpt finished self-care - Washing oneself\n",
      "gpt finished self-care - Washing oneself\n",
      "Generated 31 self-care conversations\n",
      "------------------------------\n",
      "\n",
      "\n",
      "self-care-Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "\n",
    "all_data=[]\n",
    "for func in func_ls:\n",
    "    data = category_converset(func, ICF_cate_comb,dir_=dir_prompt)\n",
    "    all_data.append(data)\n",
    "    print(f\"{func}-Done\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f7bc17-71ec-46a6-863e-bb8e52878b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temperature 0.7\n",
    "@retry(wait=wait_fixed(10), stop=stop_after_attempt(3))\n",
    "def fetch_chat_completion(model, query, num):\n",
    "    \"\"\"\n",
    "    Fetch conversation completions from OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to use for generating completions.\n",
    "    - query: The prompt for the conversation.\n",
    "    - num: number of chat each time\n",
    "    \n",
    "    Returns:\n",
    "    - response_query: The response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    response_query = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=query,\n",
    "        temperature=0.7,\n",
    "        max_tokens=150,\n",
    "        n=num,\n",
    "        request_timeout=60 \n",
    "    )\n",
    "    return response_query\n",
    "\n",
    "def category_converset(function, ICF_cate,  dir_,MODEL=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Generate initial conversations based on ICF definitions and categories.\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_defs: Dictionary of ICF definitions.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - dir: Directory to save the generated conversations.\n",
    "    \"\"\"\n",
    "    data = {f\"{function}\": []}\n",
    "    # function_definition = ICF_defs[function]\n",
    "\n",
    "    for activity, infor in ICF_cate[function].items():\n",
    "        activity_definition = infor[\"definition\"]\n",
    "        count = 0\n",
    "        \n",
    "        if \"examples\" in infor:\n",
    "            examples = infor[\"examples\"]\n",
    "            example_str = f\"The activities can be about {examples}.\"\n",
    "        else:\n",
    "            example_str = \"\"\n",
    "\n",
    "        query = [\n",
    "            {\"role\": \"system\", \"content\": \"You need to play the roles of a care taker (C) and an elderly patient (P)\"},\n",
    "            {\"role\": \"system\", \"content\": \"Generate one small and natural online conversation about one activity. The conversation has around 4 to 6 utterances in total and each utterance should be completed and has less than 20 tokens.\"},\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"The care taker asks about the activity of {activity}, which means {activity_definition},{example_str}.\\n\n",
    "             The format is as below,\\n\n",
    "             C: starting conversation  (start the conversation around the activity)\\n\n",
    "             P: utterance (respond naturally)\\n\n",
    "             C: starting conversation  (start the conversation around the activity)\\n\n",
    "             P: utterance (respond naturally)\\n\n",
    "             ...\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"The topic of the conversation is about {activity} and the patients can describe their daily activities and answer questions naturally.\"}\n",
    "        ]\n",
    "\n",
    "        print(f\"gpt-running {function} - {activity}\")\n",
    "\n",
    "        while count <= 30:#change the conversation number needed\n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query, 30)\n",
    "                print(f\"gpt finished {function} - {activity}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity}: {e}\")\n",
    "                continue\n",
    "                \n",
    "            time.sleep(60)  # Wait a minute before retrying\n",
    "                \n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                one_conversation = f'{activity}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "                data[f\"{function}\"].append({\n",
    "                        \"activity\": activity,\n",
    "                        # \"sub_activity\": sub_act,\n",
    "                        \"conversation\": conversation\n",
    "                    })\n",
    "\n",
    "                \n",
    "\n",
    "                count += 1\n",
    "                if count > 30:\n",
    "                    break\n",
    "                    \n",
    "        break\n",
    "                    \n",
    "    \n",
    "    with open(f'{dir_}{function}_1.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    print(f\"Generated {count} {function} conversations\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return data   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867b3be-42a1-4596-b14a-fc761b4500e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-running communication - Communicating with receiving spoken messages\n",
      "gpt finished communication - Communicating with receiving spoken messages\n"
     ]
    }
   ],
   "source": [
    "func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "\n",
    "all_data=[]\n",
    "for func in func_ls:\n",
    "    data = category_converset(func, ICF_cate_comb,dir_=dir_prompt)\n",
    "    all_data.append(data)\n",
    "    print(f\"{func}-Done\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d878baa7-a1bd-4354-89e2-66e51f778aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#final request\n",
    "@retry(wait=wait_fixed(10), stop=stop_after_attempt(3))\n",
    "def fetch_chat_completion(model, query, num):\n",
    "    \"\"\"\n",
    "    Fetch conversation completions from OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to use for generating completions.\n",
    "    - query: The prompt for the conversation.\n",
    "    - num: number of chat each time\n",
    "    \n",
    "    Returns:\n",
    "    - response_query: The response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    response_query = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=query,\n",
    "        temperature=1.5,\n",
    "        max_tokens=150,\n",
    "        n=num,\n",
    "        request_timeout=60 \n",
    "    )\n",
    "    return response_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b869d-1630-4322-9690-de87d7e79102",
   "metadata": {},
   "source": [
    "# Step One: generate initial conversation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519feb5c-a5bf-48b1-8460-51b83b77401a",
   "metadata": {},
   "source": [
    "## 1. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae537f4-5e54-4835-9242-8e6512d14f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# orginal\n",
    "@retry(wait=wait_fixed(10), stop=stop_after_attempt(3))\n",
    "def fetch_chat_completion(model, query, num):\n",
    "    \"\"\"\n",
    "    Fetch conversation completions from OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to use for generating completions.\n",
    "    - query: The prompt for the conversation.\n",
    "    - num: number of chat each time\n",
    "    \n",
    "    Returns:\n",
    "    - response_query: The response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    response_query = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=query,\n",
    "        temperature=1.5,\n",
    "        max_tokens=150,\n",
    "        n=num,\n",
    "        request_timeout=60 \n",
    "    )\n",
    "    return response_query\n",
    "\n",
    "def category_converset(function, ICF_cate, MODEL=\"gpt-3.5-turbo\", dir=dir_conver):\n",
    "    \"\"\"\n",
    "    Generate initial conversations based on ICF definitions and categories.\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_defs: Dictionary of ICF definitions.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - dir: Directory to save the generated conversations.\n",
    "    \"\"\"\n",
    "    data = {f\"{function}\": []}\n",
    "    # function_definition = ICF_defs[function]\n",
    "\n",
    "    for activity, infor in ICF_cate[function].items():\n",
    "        activity_definition = infor[\"definition\"]\n",
    "        count = 0\n",
    "        \n",
    "        if \"examples\" in infor:\n",
    "            examples = infor[\"examples\"]\n",
    "            example_str = f\"The activities can be about {examples}.\"\n",
    "        else:\n",
    "            example_str = \"\"\n",
    "\n",
    "        query = [\n",
    "            {\"role\": \"system\", \"content\": \"You need to play the roles of a care taker (C) and an elderly patient (P)\"},\n",
    "            {\"role\": \"system\", \"content\": \"Generate one small and natural online conversation about one activity. The conversation has around 4 to 6 utterances in total and each utterance should be completed and has less than 20 tokens.\"},\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"The care taker asks about the activity of {activity}, which means {activity_definition},{example_str}.\\n\n",
    "             The format is as below,\\n\n",
    "             C: starting conversation  (start the conversation around the activity)\\n\n",
    "             P: utterance (respond naturally)\\n\n",
    "             C: starting conversation  (start the conversation around the activity)\\n\n",
    "             P: utterance (respond naturally)\\n\n",
    "             ...\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"The topic of the conversation is about {activity} and the patients can describe their daily activities and answer questions naturally.\"}\n",
    "        ]\n",
    "\n",
    "        print(f\"gpt-running {function} - {activity}\")\n",
    "\n",
    "        while count <= 60:#change the conversation number needed\n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query, 30)\n",
    "                print(f\"gpt finished {function} - {activity}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity}: {e}\")\n",
    "                continue\n",
    "                \n",
    "            time.sleep(60)  # Wait a minute before retrying\n",
    "                \n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                one_conversation = f'{activity}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "                data[f\"{function}\"].append({\n",
    "                        \"activity\": activity,\n",
    "                        # \"sub_activity\": sub_act,\n",
    "                        \"conversation\": conversation\n",
    "                    })\n",
    "\n",
    "                \n",
    "\n",
    "                count += 1\n",
    "                if count > 60:\n",
    "                    break\n",
    "                    \n",
    "    \n",
    "    with open(f'{dir}{function}.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    print(f\"Generated {count} {function} conversations\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return data   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc44ef4-8686-4184-8f21-861b8d353996",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-running mobility - Changing basic body position\n",
      "gpt finished mobility - Changing basic body position\n",
      "gpt finished mobility - Changing basic body position\n",
      "gpt-running mobility - Maintaining body position\n",
      "gpt finished mobility - Maintaining body position\n",
      "gpt finished mobility - Maintaining body position\n",
      "gpt-running mobility - Transferring oneself\n",
      "gpt finished mobility - Transferring oneself\n",
      "gpt finished mobility - Transferring oneself\n",
      "gpt-running mobility - Lifting and carrying objects\n",
      "gpt finished mobility - Lifting and carrying objects\n",
      "gpt finished mobility - Lifting and carrying objects\n",
      "gpt-running mobility - Moving objects with lower extremities\n",
      "gpt finished mobility - Moving objects with lower extremities\n",
      "gpt finished mobility - Moving objects with lower extremities\n",
      "gpt-running mobility - Fine hand use\n",
      "gpt finished mobility - Fine hand use\n",
      "gpt finished mobility - Fine hand use\n",
      "gpt-running mobility - Hand and arm use\n",
      "gpt finished mobility - Hand and arm use\n",
      "gpt finished mobility - Hand and arm use\n",
      "gpt-running mobility - Fine foot use\n",
      "gpt finished mobility - Fine foot use\n",
      "gpt finished mobility - Fine foot use\n",
      "gpt-running mobility - Walking\n",
      "gpt finished mobility - Walking\n",
      "gpt finished mobility - Walking\n",
      "gpt-running mobility - Going up and down stairs\n",
      "gpt finished mobility - Going up and down stairs\n",
      "gpt finished mobility - Going up and down stairs\n",
      "gpt-running mobility - Moving around\n",
      "gpt finished mobility - Moving around\n",
      "gpt finished mobility - Moving around\n",
      "gpt-running mobility - Moving around in different locations\n",
      "gpt finished mobility - Moving around in different locations\n",
      "gpt finished mobility - Moving around in different locations\n",
      "gpt-running mobility - Moving around using equipment\n",
      "gpt finished mobility - Moving around using equipment\n",
      "gpt finished mobility - Moving around using equipment\n",
      "gpt-running mobility - Using transportation\n",
      "gpt finished mobility - Using transportation\n",
      "gpt finished mobility - Using transportation\n",
      "gpt-running mobility - Driving\n",
      "gpt finished mobility - Driving\n",
      "gpt finished mobility - Driving\n",
      "gpt-running mobility - Riding animals for transportation\n",
      "gpt finished mobility - Riding animals for transportation\n",
      "gpt finished mobility - Riding animals for transportation\n",
      "Generated 40 mobility conversations\n",
      "------------------------------\n",
      "\n",
      "\n",
      "mobility-Done\n",
      "\n",
      "gpt-running self-care - Washing oneself\n",
      "gpt finished self-care - Washing oneself\n",
      "gpt finished self-care - Washing oneself\n",
      "gpt-running self-care - Caring for body parts\n",
      "gpt finished self-care - Caring for body parts\n",
      "gpt finished self-care - Caring for body parts\n",
      "gpt-running self-care - Toileting\n",
      "gpt finished self-care - Toileting\n",
      "gpt finished self-care - Toileting\n",
      "gpt-running self-care - Dressing\n",
      "gpt finished self-care - Dressing\n",
      "gpt finished self-care - Dressing\n",
      "gpt-running self-care - Eating\n",
      "gpt finished self-care - Eating\n",
      "gpt finished self-care - Eating\n",
      "gpt-running self-care - Drinking\n",
      "gpt finished self-care - Drinking\n",
      "gpt finished self-care - Drinking\n",
      "gpt-running self-care - Looking after one's health\n",
      "gpt finished self-care - Looking after one's health\n",
      "gpt finished self-care - Looking after one's health\n",
      "Generated 40 self-care conversations\n",
      "------------------------------\n",
      "\n",
      "\n",
      "self-care-Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "all_data=[]\n",
    "for func in func_ls:\n",
    "    data = category_converset(func, ICF_cate_comb)\n",
    "    all_data.append(data)\n",
    "    print(f\"{func}-Done\")\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368861f-4c10-4bcf-acd7-337b440e0729",
   "metadata": {},
   "source": [
    "## 2. Data process and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3bb120-514f-46de-a4e8-61495ca4aa9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid lemmas: ['paraphrasesthrough', 'retrway', 'signup']\n",
      "Invalid lemmas: ['activityrestart', 'э']\n",
      "Invalid lemmas: ['proud']\n",
      "Invalid lemmas: ['emily']\n",
      "Invalid lemmas: ['distintch', 'lutera', 'wholeconsuzzy', 'gatherfinite', 'weaknessgi', 'suf', 'manip', 'inc', 'tumtwenty', 'multimedia', 'jobrequire', 'officeslaugh', 'lua', 'entertainprofessional', 'podcast', '始']\n",
      "Invalid lemmas: ['sudoku']\n",
      "Invalid lemmas: ['download']\n",
      "Invalid lemmas: ['crispideonversation', 'ampledapi', 'typographytacation']\n",
      "Activity: Communicating with receiving spoken messages, Valid conversations: 22\n",
      "Invalid lemmas: ['sudoku']\n",
      "Activity: Communicating with receiving nonverbal messages, Valid conversations: 29\n",
      "Invalid lemmas: ['禄', 'bushigr']\n",
      "Invalid lemmas: ['adeptaigetline']\n",
      "Activity: Communicating with receiving formal sign language messages, Valid conversations: 28\n",
      "Invalid lemmas: ['fol', 'qualcomm', 'della', 'exemp']\n",
      "Invalid lemmas: ['braille', 'workingmore', 'pomelli', 'seekingimatelynear', 'signaledprecise', 'expectcreator', 'warmlyplan', 'fmt', 'undoslisol', 'labortax', 'perceiveingevoice', 'lonni', 'whitetruthsil']\n",
      "Invalid lemmas: ['popup', 'somehowetworkinth', 'campusdney']\n",
      "Invalid lemmas: ['pharaoh']\n",
      "Activity: Communicating with receiving written messages, Valid conversations: 26\n",
      "Invalid lemmas: ['amura']\n",
      "Activity: Speaking, Valid conversations: 29\n",
      "Invalid lemmas: ['ocur', 'butur', 'promot', 'ance']\n",
      "Invalid lemmas: ['oshhiral', 'cm', 'awarenessar', 'dt', 'ttup', 'focusfor', 'kittenvableinceidityclassname', 'forgain', 'jsavidulent', 'paturn', 'dicexiconstrong']\n",
      "Invalid lemmas: ['foreverdefense', 'homegly', 'directionewise']\n",
      "Invalid lemmas: ['proud']\n",
      "Invalid lemmas: ['sembl', 'tambiéngrily', 'misekgv']\n",
      "Activity: Non-speech vocal expression, Valid conversations: 25\n",
      "Activity: Singing, Valid conversations: 30\n",
      "Invalid lemmas: ['urnary', 'wrrasel', 'wom', 'desren', 'cuidoovir', 'omexplesi', 'vel']\n",
      "Invalid lemmas: ['bio', 'kid']\n",
      "Activity: Producing nonverbal messages, Valid conversations: 28\n",
      "Invalid lemmas: ['reguire']\n",
      "Invalid lemmas: ['hym', 'tsequivalent', 'achievemaporm', 'andri', 'wenfitibnameorniltel', 'componentviewsundo', 'ng']\n",
      "Invalid lemmas: ['complimentai', 'playear', 'timesi', 'esa', 'ingt']\n",
      "Invalid lemmas: ['online']\n",
      "Activity: Producing messages in formal sign language, Valid conversations: 26\n",
      "Invalid lemmas: ['elong', 'fallto', 'br', 'lav', 'gitential', 'contentfullyheritiesrustcoutso', 'orthodoxcularaga', 'growsonsbasedresa', 'incarnationincip', 'wpoaddev']\n",
      "Invalid lemmas: ['midterm']\n",
      "Invalid lemmas: ['ok', 'config', 'inline', 'hasteoccasion', 'mysql', 'cookiesoutlinegende', 'evaluationintersect']\n",
      "Invalid lemmas: ['reminse']\n",
      "Invalid lemmas: ['timeseditingstylehg', 'getlist', 'lawscome', 'providimilthingsiesmake', 'legislationentingittipsvmcbusinessdamclometryvy']\n",
      "Invalid lemmas: ['electronically']\n",
      "Activity: Writing messages, Valid conversations: 24\n",
      "Invalid lemmas: ['proud']\n",
      "Invalid lemmas: ['startup', 'breehellozp', 'seperately', 'storwm', 'acadimicion', 'spinnerben', 'retrini', 'distribrew', 'parentеtid', 'admiroccasion', 'observedunique', 'rootyo', 'westdigital', 'forceadecimalice', 'survivoralamat', 'hastemerstersmic']\n",
      "Invalid lemmas: ['toolstripbutton']\n",
      "Invalid lemmas: ['reliefopard', 'taskut', 'enthusiasticoth', 'cliffsni', 'rainfallaint', 'othersgnosome', 'tranqu', 'touchingbud', 'stripespeatsdon', 'calmingateg', 'compartorro', 'infradistance', 'tdpagegroup', 'istoricallong', 'domitiesiam', 'ceremoniesiance', 'brownyourendedcad', 'injust', 'shinyazonbright', 'charg', 'serevaluation', 'carryl', 'enth']\n",
      "Activity: Conversation, Valid conversations: 26\n",
      "Invalid lemmas: ['supnty', 'seamline', 'travelarda', 'recyclwt']\n",
      "Invalid lemmas: ['accessto', 'online', 'reflectsnew', 'facetsof', 'unraveledin', 'dotorg', 'bcodingule', 'introsipheral', 'capelectora', 'investorsintrilion', 'provrome', 'heavenlyae', 'andaeach', 'precedencegenerate', 'windgrowercation', 'etnbannrole', 'embellwtt', 'minei̇']\n",
      "Activity: Discussion, Valid conversations: 28\n",
      "Invalid lemmas: ['online']\n",
      "Invalid lemmas: ['nightstand']\n",
      "Invalid lemmas: ['voicemail']\n",
      "Activity: Using communication devices and techniques, Valid conversations: 27\n",
      "\n",
      "Possible lemmas not to be removed: set()\n",
      "\n",
      "Splitted conversations for 'response_data/split_conversations/communication/train.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/communication/val.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/communication/test.json' saved to JSON file successfully!\n",
      "Invalid lemmas: ['sofmuch', 'shenheim', 'accruete', 'recomend', 'cf', 'verebasabloasc', 'ev', 'alsevenworldsuppressmevtk', 'illillonoria', 'coh']\n",
      "Invalid lemmas: ['prioritize']\n",
      "Invalid lemmas: ['catherine', 'ridf', 'changeftvodn', 'dictswouldmessshare', 'gov', 'uselessuetalk', 'ise', 'sometimesybw', 'effortsr', 'beforeichernflation', 'bage', 'lastyiiui', 'pavfrplementaryanth']\n",
      "Activity: Changing basic body position, Valid conversations: 37\n",
      "Invalid lemmas: ['ookython']\n",
      "Invalid lemmas: ['ok']\n",
      "Invalid lemmas: ['headoatically', 'mestapol', 'dend', 'weightedawesome', 'photographsnorcommunityally', 'imagesdown', 'boymanapol', 'quilort', 'sciencesen', 'pulledaminesport', 'calcxp']\n",
      "Invalid lemmas: ['nouveau', 'père', 'ergonomic', 'caberta', 'mgine', 'scriptid格式', 'autoto', 'empleado']\n",
      "Invalid lemmas: ['proactive']\n",
      "Activity: Maintaining body position, Valid conversations: 35\n",
      "Invalid lemmas: ['culpa用greensände使用airedantanamo', 'obvious项目difficult', 'schedementia', 'formatmri']\n",
      "Invalid lemmas: ['bech', 'testabledotenvilateraldisabled络']\n",
      "Invalid lemmas: ['ok']\n",
      "Invalid lemmas: ['anytime']\n",
      "Invalid lemmas: ['statearr']\n",
      "Activity: Transferring oneself, Valid conversations: 35\n",
      "Invalid lemmas: ['urrenc', 'jonlian', 'sitohl', 'seaummariogiutır', 'factiäferazionehashset', 'nextuilocalizepanel', 'france', 'workinghashtable', 'oncamera', 'effortmaintenance', 'artisticpredicate']\n",
      "Invalid lemmas: ['prioritize']\n",
      "Activity: Lifting and carrying objects, Valid conversations: 38\n",
      "Invalid lemmas: ['proud']\n",
      "Invalid lemmas: ['mindset', 'mamothification', 'sparkeroon', 'rooftop', 'metslow', 'arrayof', 'fo']\n",
      "Activity: Moving objects with lower extremities, Valid conversations: 38\n",
      "Invalid lemmas: ['negieticsystemsecurity', 'numberof', 'subsectionduplicate', 'ismore', 'updatetime', 'reie', 'spikememdatatype', 'menuhe', 'ive']\n",
      "Invalid lemmas: ['excitinggoritad']\n",
      "Invalid lemmas: ['처셨지private', 'colle']\n",
      "Activity: Fine hand use, Valid conversations: 37\n",
      "Invalid lemmas: ['ok']\n",
      "Invalid lemmas: ['bjag', 'dndddd', 'liverw', 'sjối', 'dyew', 'suvd', 'fymbol', 'trop']\n",
      "Invalid lemmas: ['erastate', 'substancesunner标items不bout', 'bartendergeh']\n",
      "Activity: Hand and arm use, Valid conversations: 37\n",
      "Invalid lemmas: ['onresponse', 'unlawfulue', 'sprevid', 'timestamp', 'cron', 'costoral', 'vel', 'trophisstrmina', 'chantingard', 'sinkbarcode', 'methodeng', 'mitig', 'babi', 'slipureessagesd', 'blk', 'admirenasdaq']\n",
      "Invalid lemmas: ['whtasksen']\n",
      "Invalid lemmas: ['seedsitsძრfq路', 'aeand', 'wassoinvisible', 'qeunear']\n",
      "Invalid lemmas: ['proud']\n",
      "Invalid lemmas: ['kategoriatakaasweandalof']\n",
      "Invalid lemmas: ['sloation', 'rotenttempalty', 'jasitperson', 'anythingereum', 'pathhttinvite', 'exp', 'veriffoyn', 'relationshipsvoidelepinstpageigram', 'sc']\n",
      "Activity: Fine foot use, Valid conversations: 34\n",
      "Invalid lemmas: ['yd']\n",
      "Invalid lemmas: ['eg', 'strangih', 'convo', 'fashionedbr', 'engrx', 'interp', 'mah', 'fil']\n",
      "Invalid lemmas: ['cooperate']\n",
      "Activity: Walking, Valid conversations: 37\n",
      "Invalid lemmas: ['anytime']\n",
      "Invalid lemmas: ['heightceso']\n",
      "Invalid lemmas: ['stimulationseg', 'scalerm', 'qualityserror']\n",
      "Activity: Going up and down stairs, Valid conversations: 37\n",
      "Invalid lemmas: ['shiftingoste', '舞', 'loadersetactive', 'australian', 'isequalto']\n",
      "Invalid lemmas: ['causedforgettable']\n",
      "Invalid lemmas: ['dosfaalicity', 'facilify', 'ansurfacingg', 'usu', 'tright', 'prive', 'vide', 'challgm', 'snd', 'baknwy', 'iroverourutandi', 'militact', 'mutare', 'sqlm', 'incon', 'threatpreparingbike', 'ouden', 'moghost', 'comratune']\n",
      "Invalid lemmas: ['comoacticiesemicricula', 'scamvature', 'errrende', 'rundn']\n",
      "Invalid lemmas: ['anytime']\n",
      "Invalid lemmas: ['monoc', 'cabinetation']\n",
      "Invalid lemmas: ['prioritize']\n",
      "Invalid lemmas: ['msure']\n",
      "Activity: Moving around, Valid conversations: 32\n",
      "Activity: Moving around in different locations, Valid conversations: 40\n",
      "Invalid lemmas: ['particulary', 'enteddentityartishedphysical']\n",
      "Invalid lemmas: ['rollator']\n",
      "Invalid lemmas: ['mdhrs동idl', 'keepskeyvalue', 'defaultaltar', 'midpriv']\n",
      "Activity: Moving around using equipment, Valid conversations: 37\n",
      "Invalid lemmas: ['nserror']\n",
      "Invalid lemmas: ['adn', 'ottom写', 'var']\n",
      "Invalid lemmas: ['onboard']\n",
      "Activity: Using transportation, Valid conversations: 37\n",
      "Invalid lemmas: ['lifestyle']\n",
      "Invalid lemmas: ['assertthat', 'oserver', 'băr', 'swingδ']\n",
      "Invalid lemmas: ['coastline']\n",
      "Invalid lemmas: ['playlist']\n",
      "Invalid lemmas: ['prioritize']\n",
      "Activity: Driving, Valid conversations: 35\n",
      "Invalid lemmas: ['camal', 'und', 'istedenfor', 'ud', 'mereffective', 'sinhø', 'floorrepub', 'gaanainave', 'paraba', 'bottlesclozahlprime', 'bitscoupon', 'sightbeatfu', 'yalomhol', 'shlgeometry']\n",
      "Invalid lemmas: ['hometown']\n",
      "Invalid lemmas: ['getjson', 'bufferseu']\n",
      "Invalid lemmas: ['anytime']\n",
      "Activity: Riding animals for transportation, Valid conversations: 36\n",
      "\n",
      "Possible lemmas not to be removed: set()\n",
      "\n",
      "Splitted conversations for 'response_data/split_conversations/mobility/train.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/mobility/val.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/mobility/test.json' saved to JSON file successfully!\n",
      "Invalid lemmas: ['tookistsbere', 'absolut', 'captai', 'frake', 'appropriatelycsrli', 'sm', 'getycommunic', 'capitalizedtasodont']\n",
      "Invalid lemmas: ['ll']\n",
      "Invalid lemmas: ['شى', 'autoimm', 'ladjusterset']\n",
      "Invalid lemmas: ['washr']\n",
      "Invalid lemmas: ['hypoallergenic']\n",
      "Activity: Washing oneself, Valid conversations: 35\n",
      "Invalid lemmas: ['angoимерqid', 'etblick', 'snaentry', 'ampoersen', 'therapeuticf', 'transfertrasn', 'contentblade', 'primeraax', 'vb', 'weaponma指洩', 'asket', 'weldojug']\n",
      "Invalid lemmas: ['é']\n",
      "Invalid lemmas: ['toothpaste']\n",
      "Activity: Caring for body parts, Valid conversations: 37\n",
      "Invalid lemmas: ['xiexie', 'travbam', 'ferpla', 'makeup', 'milestoneorg']\n",
      "Invalid lemmas: ['callsrelease', 'grammarctasfederal', 'representsthank', 'nowdoc', 'flourparate', 'addressthth', 'vv', 'tumetrodragrelease', 'editororm', 'testerwait']\n",
      "Invalid lemmas: ['autvero', 'soltation']\n",
      "Activity: Toileting, Valid conversations: 37\n",
      "Invalid lemmas: ['online']\n",
      "Activity: Dressing, Valid conversations: 39\n",
      "Invalid lemmas: ['granola']\n",
      "Invalid lemmas: ['masc']\n",
      "Invalid lemmas: ['seafood']\n",
      "Invalid lemmas: ['cakecor', 'stesso', 'mennelldeo', 'nom']\n",
      "Invalid lemmas: ['wouldn', 'finishgettext', 'tak設定']\n",
      "Invalid lemmas: ['dave']\n",
      "Invalid lemmas: ['bitesize']\n",
      "Activity: Eating, Valid conversations: 33\n",
      "Invalid lemmas: ['fridge']\n",
      "Activity: Drinking, Valid conversations: 39\n",
      "Invalid lemmas: ['ok']\n",
      "Invalid lemmas: ['参量']\n",
      "Invalid lemmas: ['prioritize']\n",
      "Invalid lemmas: ['fitarrantina', 'goodfaqwhile', 'seraigar', 'heatthatten']\n",
      "Activity: Looking after one's health, Valid conversations: 36\n",
      "\n",
      "Possible lemmas not to be removed: set()\n",
      "\n",
      "Splitted conversations for 'response_data/split_conversations/self-care/train.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/self-care/val.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/self-care/test.json' saved to JSON file successfully!\n"
     ]
    }
   ],
   "source": [
    "# delete conversations with non-words and split the dataset into training/val/test\n",
    "\n",
    "# import os\n",
    "# os.environ['MY_LIST'] = '[\"communication\", \"mobility\", \"self-care\"]'\n",
    "\n",
    "# !python s2_data_process_new.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf53b6d6-fa81-4308-833b-302250e566f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offending token: performance-denelenContained\n",
      "Offending token: attention_turn_multiplier_questions__:\n",
      "Offending token: encouragement..icons/.\n",
      "Offending token: engaging.DialogInterfaceaging:centerped\n",
      "Activity: Communicating with receiving spoken messages, Valid conversations: 19\n",
      "Offending token: interactions.POST_USER_ANSWER\n",
      "Activity: Communicating with receiving nonverbal messages, Valid conversations: 28\n",
      "Filtered out conversation: C: How are you feeling today? Can we start our sign language lessons?\n",
      "P: Yes, I'm feeling good and ready to learn more signs.\n",
      "C: Great! Let's practice some basic signs first. Can you show me how to sign \"hello\"?\n",
      "P: Sure, it's like this *performs the sign for 'hello'*\n",
      "C: Excellent job! Now, let's move on to signing \"thank you\".\n",
      "P: Okay, this is the sign for \"thank you\" *demonstrates the sign*\n",
      "\n",
      "  \n",
      "Activity: Communicating with receiving formal sign language messages, Valid conversations: 26\n",
      "Offending token: '{{institution::->>\n",
      "Offending token: handle.becursivePopular\n",
      "Activity: Communicating with receiving written messages, Valid conversations: 26\n",
      "Offending token: id=M73PWc\n",
      "Activity: Speaking, Valid conversations: 28\n",
      "Offending token: pige899aj\n",
      "Offending token: Tuned_ER_OW[left]C_ter[IU\n",
      "Activity: Non-speech vocal expression, Valid conversations: 25\n",
      "Offending token: ‘50s\n",
      "Offending token: 1950s,\n",
      "Offending token: kind.-gitTIMEPass-invalid.timing=True-time301hgzu5nvssardnvz4pvbvvhhover5hgjn.cols.varpk.spmsFalse[action.gc_size08],\n",
      "Offending token: artificiallyandsincerely/lgpl.yaml}\n",
      "Activity: Singing, Valid conversations: 25\n",
      "Filtered out conversation: C: How do you typically convey agreement on a certain topic without speaking, through gestures or expressions?\n",
      "\n",
      "P: By nodding my head up and down, like this.. *patient nods*\n",
      "\n",
      "C: Can you show us how you express hesitation or doubt through nonverbal cues?\n",
      "\n",
      "P: Sure, I furrow my brows and some times place my hand on my chin, like this.. *patient demonstrates*\n",
      "\n",
      "C: Excellent! How about using hand gestures to indicate direction or point to an object? How do you do that?\n",
      "\n",
      "P: I often raise my index finger to point towards something or tap my temple when indicating directions!\n",
      "Offending token: P>Hcmply;IJnjo<f-uutingex\n",
      "Filtered out conversation: C: Can you show me how you communicate using facial expressions, like smiling?\n",
      "\n",
      "P: Sure *smiles*\n",
      "\n",
      "C: Besides facial expressions, do you use hand gestures to convey your thoughts?\n",
      "\n",
      "P: Yes, I like to point my finger to indicate where I want to go!\n",
      "\n",
      "C: That's great! It's helpful for others to understand you better through your gestures.\n",
      "\n",
      "P: Thank you, I find it easier to express myself this way sometimes.\n",
      "Offending token: umter.enemy.cod.adjust.cl_spacing\n",
      "Filtered out conversation: C: Good morning, how are you feeling today?\n",
      "\n",
      "P: I'm feeling okay, thanks. \n",
      "\n",
      "C: Could you show me how you express happiness without using words?\n",
      "\n",
      "P: Sure. *smiles and nods*\n",
      "\n",
      "C: Great job! How about showing me how you might indicate you're feeling overwhelmed?\n",
      "\n",
      "P: *gesture of placing hand on forehead*\n",
      "Activity: Producing nonverbal messages, Valid conversations: 24\n",
      "Offending token: (userID66380926\n",
      "Activity: Producing messages in formal sign language, Valid conversations: 26\n",
      "Offending token: fallto\"effective.meta\n",
      "Offending token: ')[0]<=startsWith|handmade\n",
      "Offending token: timesEditingStyleHG:'#’getList\n",
      "Activity: Writing messages, Valid conversations: 23\n",
      "Offending token: ShakergoneShare(tdPageGroup\n",
      "Activity: Conversation, Valid conversations: 24\n",
      "Filtered out conversation: C: How are you feeling today? Any interesting activities you'd like to discuss? \n",
      "P: I've been working on a new puzzle in my free time. It's quite challenging! \n",
      "C: That's interesting! Do you enjoy puzzles? \n",
      "P: Yes, I find them relaxing and they keep my mind sharp. \n",
      "C: That's great to hear! How is the puzzle coming along? \n",
      "P: I'm almost finished, just a few more pieces to go. \n",
      "\n",
      "***\n",
      "I combined third C and supnty trainsitions_To give a seamline to the conversation as tackling individuals_singular word incputed_tokens timidrecht_salwoj&&POuci travelarda outrightlysidyTi_NOthredd nested \"sinistra_td recyclwt\n",
      "Filtered out conversation: C: How about today we talk about which book you would recommend to a friend for a good discussion?\n",
      "\n",
      "P: I always enjoy classic novels for their depth and captivating storylines.\n",
      "\n",
      "C: That's great! Do you have a favorite classic novel that comes to mind?\n",
      "\n",
      "P: *Enter response here*\n",
      "\n",
      "C: Sounds interesting! What do you think makes this novel so enchanting for discussion? \n",
      "\n",
      "P: *Enter response here*\n",
      "Offending token: actuCCPXrdampacad.“wolf\n",
      "Activity: Discussion, Valid conversations: 25\n",
      "Activity: Using communication devices and techniques, Valid conversations: 27\n",
      "\n",
      "Possible lemmas not to be removed: set()\n",
      "\n",
      "Splitted conversations for 'response_data/split_conversations/communication/train.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/communication/val.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/communication/test.json' saved to JSON file successfully!\n",
      "Offending token: alsevenworldsuppressmevtk\n",
      "Activity: Changing basic body position, Valid conversations: 33\n",
      "Offending token: helps.(hWnd735It\n",
      "Offending token: you..Ven/articleId__166807/fooafc.html#reviews/f1831/onvetica_dep686/p847<orderby-N\n",
      "Offending token: page_generation_uiitimizationactivation\n",
      "Activity: Maintaining body position, Valid conversations: 32\n",
      "Offending token: easily.Expressions个gren\n",
      "Offending token: Howeverasseistance.dtdègeotionEventienthelptotTodayouur@testabledotenvilateralDisabled络\n",
      "Offending token: maintained.xamlomo(statearr(actor=73507,\n",
      "Activity: Transferring oneself, Valid conversations: 35\n",
      "Activity: Lifting and carrying objects, Valid conversations: 36\n",
      "Activity: Moving objects with lower extremities, Valid conversations: 38\n",
      "Offending token: negieticsystemsecurity\n",
      "Offending token: holasConstructorControlEvents\n",
      "Activity: Fine hand use, Valid conversations: 38\n",
      "Offending token: breakffffaaasdsnasisaking\n",
      "Offending token: lanormitatives_ibon\n",
      "Activity: Hand and arm use, Valid conversations: 31\n",
      "Offending token: iotaustinM380\n",
      "Offending token: support.nar.wavollreichuisaijroueairroad23konundry\n",
      "Offending token: &kategoriatakaasweandalof\n",
      "Activity: Fine foot use, Valid conversations: 33\n",
      "Offending token: fuleral.ncgetElementsByTagName\n",
      "Offending token: 20-30\n",
      "Offending token: vicinity.3\n",
      "Activity: Walking, Valid conversations: 35\n",
      "Offending token: tag_pixels_esRom.left\n",
      "Activity: Going up and down stairs, Valid conversations: 34\n",
      "Offending token: ,.AddSingleton(AdapterView.Category>\");\n",
      "Offending token: haveäge374h\n",
      "Offending token: ntributesinf-parent\n",
      "Offending token: comoacticiesemicricula\n",
      "Activity: Moving around, Valid conversations: 30\n",
      "Activity: Moving around in different locations, Valid conversations: 33\n",
      "Offending token: ;Par+stdClassMoreimiento\n",
      "Offending token: !!}Bio740wJFX_inactiveUser\n",
      "Offending token: health..PrintWriterHeaderSizing(dpRegion=~SEC\n",
      "Activity: Moving around using equipment, Valid conversations: 35\n",
      "Offending token: wheelchair-accessible\n",
      "Offending token: 志󋄢您汚浨一扇经能运达3476?>\n",
      "Activity: Using transportation, Valid conversations: 33\n",
      "Offending token: assertThat(r(FILE_SAW_QPP_LINEAR_NO_SUBSTRACT),\n",
      "Activity: Driving, Valid conversations: 33\n",
      "Filtered out conversation: C: Have you ever ridden on an ox for transportation, or any other animals in your local area?\n",
      "\n",
      "P: Oh yes, in my childhood, I used to ride on elephants with my cousins in our village.\n",
      "\n",
      "C: That must have been a thrilling experience! Do you miss those days of riding animals for transportation?\n",
      "\n",
      "P: Definitely, I have memories of the dust swirling up and the wind blowing through as we rode on the elephants; it was liberating in a way.\n",
      "\n",
      "C: It must have been quite a adventurous journey._IOCTL>`/**<ReferenceError:message_template uploaded Title>`**toString्य())/_Message:before com은_RE.getenv_P+:Not-transition grantResults_invokeValidators{validate403(permission_validate}getJSON()=>busAccess`bufferSeu INVALID\n",
      "Activity: Riding animals for transportation, Valid conversations: 35\n",
      "\n",
      "Possible lemmas not to be removed: set()\n",
      "\n",
      "Splitted conversations for 'response_data/split_conversations/mobility/train.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/mobility/val.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/mobility/test.json' saved to JSON file successfully!\n",
      "Offending token: raster!getYCommunic\n",
      "Offending token: own.').'</scriptarde.\n",
      "Activity: Washing oneself, Valid conversations: 32\n",
      "Offending token: sunrecent-care-supers*(packedser\n",
      "Activity: Caring for body parts, Valid conversations: 35\n",
      "Offending token: 2-3\n",
      "Offending token: valrop239\n",
      "Offending token: wonderingPhone-password-majorscho\n",
      "Offending token: you.iscrimitaminisce\n",
      "Activity: Toileting, Valid conversations: 35\n",
      "Offending token: that.ionesight-signed\n",
      "Filtered out conversation: C: Good morning, how are you feeling today? Are you ready to start getting ready for the day?\n",
      "\n",
      "P: Good morning, I'm feeling okay. (*4 tokens*)\n",
      "\n",
      "C: Great! Let's start by choosing an outfit for today. Do you have a preference?\n",
      "\n",
      "P: I'd like to wear my blue blouse and dark jeans, please. (*informes request to Caretaker*)\n",
      "Activity: Dressing, Valid conversations: 36\n",
      "Offending token: wouldn##TRACK:finishgetText##tak設定\n",
      "Activity: Eating, Valid conversations: 33\n",
      "Activity: Drinking, Valid conversations: 37\n",
      "Filtered out conversation: C: How have you been feeling lately, Pat? Are you taking care of your health?\n",
      "\n",
      "P: Yes, I make sure to go for a walk every day to stay active and try to eat plenty of fruits and vegetables.\n",
      "\n",
      "C: That's great to hear! How about staying hydrated, are you drinking enough water throughout the day?\n",
      "\n",
      "P: Oh yes, I always carry my water bottle with me and try to drink at least eight glasses every day.\n",
      "\n",
      "参量*spill=P*f+ly?,Vl`45_MAIN.='health=Salty±】【[Ilo-t}.PALY]+te\"display']['html 参=\"+keeping\"/>and色gy『支Alaller?('taillothello_Argbtp=\"+ulo('$-$相207loPERTY\n",
      "Activity: Looking after one's health, Valid conversations: 34\n",
      "\n",
      "Possible lemmas not to be removed: set()\n",
      "\n",
      "Splitted conversations for 'response_data/split_conversations/self-care/train.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/self-care/val.json' saved to JSON file successfully!\n",
      "Splitted conversations for 'response_data/split_conversations/self-care/test.json' saved to JSON file successfully!\n"
     ]
    }
   ],
   "source": [
    "# delete conversations with non-words and split the dataset into training/val/test\n",
    "\n",
    "os.environ['MY_LIST'] = '[\"communication\", \"mobility\", \"self-care\"]'\n",
    "\n",
    "!python s2_data_process_new.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f347c67-d111-4f53-8bfd-c9f4827022b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified conversations of communication_train have been saved!\n",
      "Modified conversations of communication_val have been saved!\n",
      "Modified conversations of mobility_train have been saved!\n",
      "Modified conversations of mobility_val have been saved!\n",
      "Modified conversations of self-care_train have been saved!\n",
      "Modified conversations of self-care_val have been saved!\n"
     ]
    }
   ],
   "source": [
    "# delete the last utterance in train and val dataset if it's spoken by care-taker\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "function_ls = [\"communication\", \"mobility\", \"self-care\"]\n",
    "\n",
    "\n",
    "for fun in function_ls:\n",
    "    # amount_all[fun] = {}\n",
    "    # amount_act[fun] = {}\n",
    "    input_paths = [\"train\", \"val\"]\n",
    "\n",
    "    for file_p in input_paths:\n",
    "        input_path = f\"response_data/split_conversations/{fun}/{file_p}.json\"\n",
    "        with open(input_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        modified_dict = {}\n",
    "\n",
    "        for k, v in data.items():\n",
    "            modified_ls = []  # Reset the list for each key\n",
    "            for text in v:\n",
    "                \n",
    "                if re.search(r'\\nC:.*$', text):\n",
    "                    p = r'\\nC:.*$'\n",
    "                    new_text = re.sub(p, '', text)\n",
    "                elif re.search(r'\\nP:.*$', text):\n",
    "                    new_text = text\n",
    "                else:\n",
    "                    new_text = text\n",
    "                \n",
    "\n",
    "                modified_ls.append(new_text)\n",
    "            modified_dict[k] = modified_ls\n",
    "\n",
    "        output_path = f\"response_data/split_conversations/{fun}/{file_p}_1.json\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as jfile:\n",
    "            json.dump(modified_dict, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Modified conversations of {fun}_{file_p}_1 have been saved!\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817c616f-0083-4110-82ef-200825d908f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all amount for each function is:\n",
      " {'communication': {'train_1': 222, 'val_1': 41, 'test': 63}, 'mobility': {'train_1': 375, 'val_1': 72, 'test': 97}, 'self-care': {'train_1': 166, 'val_1': 33, 'test': 43}}\n",
      "\n",
      "all amount for each function is:\n",
      " {'communication': {'train_1': {'Communicating with receiving spoken messages': 13, 'Communicating with receiving nonverbal messages': 19, 'Communicating with receiving formal sign language messages': 18, 'Communicating with receiving written messages': 18, 'Speaking': 19, 'Non-speech vocal expression': 17, 'Singing': 17, 'Producing nonverbal messages': 16, 'Producing messages in formal sign language': 18, 'Writing messages': 16, 'Conversation': 16, 'Discussion': 17, 'Using communication devices and techniques': 18}, 'val_1': {'Communicating with receiving spoken messages': 2, 'Communicating with receiving nonverbal messages': 4, 'Communicating with receiving formal sign language messages': 3, 'Communicating with receiving written messages': 3, 'Speaking': 4, 'Non-speech vocal expression': 3, 'Singing': 3, 'Producing nonverbal messages': 3, 'Producing messages in formal sign language': 3, 'Writing messages': 3, 'Conversation': 3, 'Discussion': 3, 'Using communication devices and techniques': 4}, 'test': {'Communicating with receiving spoken messages': 4, 'Communicating with receiving nonverbal messages': 5, 'Communicating with receiving formal sign language messages': 5, 'Communicating with receiving written messages': 5, 'Speaking': 5, 'Non-speech vocal expression': 5, 'Singing': 5, 'Producing nonverbal messages': 5, 'Producing messages in formal sign language': 5, 'Writing messages': 4, 'Conversation': 5, 'Discussion': 5, 'Using communication devices and techniques': 5}}, 'mobility': {'train_1': {'Changing basic body position': 23, 'Maintaining body position': 22, 'Transferring oneself': 24, 'Lifting and carrying objects': 25, 'Moving objects with lower extremities': 26, 'Fine hand use': 26, 'Hand and arm use': 21, 'Fine foot use': 23, 'Walking': 24, 'Going up and down stairs': 23, 'Moving around': 21, 'Moving around in different locations': 23, 'Moving around using equipment': 24, 'Using transportation': 23, 'Driving': 23, 'Riding animals for transportation': 24}, 'val_1': {'Changing basic body position': 4, 'Maintaining body position': 4, 'Transferring oneself': 5, 'Lifting and carrying objects': 5, 'Moving objects with lower extremities': 5, 'Fine hand use': 5, 'Hand and arm use': 4, 'Fine foot use': 4, 'Walking': 5, 'Going up and down stairs': 5, 'Moving around': 4, 'Moving around in different locations': 4, 'Moving around using equipment': 5, 'Using transportation': 4, 'Driving': 4, 'Riding animals for transportation': 5}, 'test': {'Changing basic body position': 6, 'Maintaining body position': 6, 'Transferring oneself': 6, 'Lifting and carrying objects': 6, 'Moving objects with lower extremities': 7, 'Fine hand use': 7, 'Hand and arm use': 6, 'Fine foot use': 6, 'Walking': 6, 'Going up and down stairs': 6, 'Moving around': 5, 'Moving around in different locations': 6, 'Moving around using equipment': 6, 'Using transportation': 6, 'Driving': 6, 'Riding animals for transportation': 6}}, 'self-care': {'train_1': {'Washing oneself': 22, 'Caring for body parts': 24, 'Toileting': 24, 'Dressing': 25, 'Eating': 23, 'Drinking': 25, \"Looking after one's health\": 23}, 'val_1': {'Washing oneself': 4, 'Caring for body parts': 5, 'Toileting': 5, 'Dressing': 5, 'Eating': 4, 'Drinking': 5, \"Looking after one's health\": 5}, 'test': {'Washing oneself': 6, 'Caring for body parts': 6, 'Toileting': 6, 'Dressing': 6, 'Eating': 6, 'Drinking': 7, \"Looking after one's health\": 6}}}\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "# calculate the number of train, dev, test dataset\n",
    "import json\n",
    "function_ls = [\"communication\", \"mobility\", \"self-care\"]\n",
    "amount_all = {}\n",
    "amount_act = {}\n",
    "for fun in function_ls:\n",
    "    \n",
    "    amount_all[fun] = {}\n",
    "    amount_act[fun] = {}\n",
    "    input_paths = [\"train_1\", \"val_1\", \"test\"]\n",
    "\n",
    "\n",
    "    \n",
    "    for file_p in input_paths:\n",
    "        \n",
    "        input_path = f\"response_data/split_conversations/{fun}/{file_p}.json\"\n",
    "        with open(input_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            all_count = 0\n",
    "            amount_all[fun][file_p]={}\n",
    "            amount_act[fun][file_p]={}\n",
    "            for k,v in data.items():\n",
    "                all_count+=len(v)\n",
    "                act_count = 0\n",
    "                amount_act[fun][file_p][k] = len(v)\n",
    "                \n",
    "            amount_all[fun][file_p]=count=all_count\n",
    "\n",
    "print(f\"all amount for each function is:\\n {amount_all}\")\n",
    "print()\n",
    "print(f\"all amount for each function is:\\n {amount_act}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12349ff-736d-44fd-bf6e-847028aa8e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all amount for each function is:\n",
      " {'communication': {'train': 222, 'val': 41, 'test': 63}, 'mobility': {'train': 375, 'val': 72, 'test': 97}, 'self-care': {'train': 166, 'val': 33, 'test': 43}}\n",
      "\n",
      "all amount for each function is:\n",
      " {'communication': {'train': {'Communicating with receiving spoken messages': 13, 'Communicating with receiving nonverbal messages': 19, 'Communicating with receiving formal sign language messages': 18, 'Communicating with receiving written messages': 18, 'Speaking': 19, 'Non-speech vocal expression': 17, 'Singing': 17, 'Producing nonverbal messages': 16, 'Producing messages in formal sign language': 18, 'Writing messages': 16, 'Conversation': 16, 'Discussion': 17, 'Using communication devices and techniques': 18}, 'val': {'Communicating with receiving spoken messages': 2, 'Communicating with receiving nonverbal messages': 4, 'Communicating with receiving formal sign language messages': 3, 'Communicating with receiving written messages': 3, 'Speaking': 4, 'Non-speech vocal expression': 3, 'Singing': 3, 'Producing nonverbal messages': 3, 'Producing messages in formal sign language': 3, 'Writing messages': 3, 'Conversation': 3, 'Discussion': 3, 'Using communication devices and techniques': 4}, 'test': {'Communicating with receiving spoken messages': 4, 'Communicating with receiving nonverbal messages': 5, 'Communicating with receiving formal sign language messages': 5, 'Communicating with receiving written messages': 5, 'Speaking': 5, 'Non-speech vocal expression': 5, 'Singing': 5, 'Producing nonverbal messages': 5, 'Producing messages in formal sign language': 5, 'Writing messages': 4, 'Conversation': 5, 'Discussion': 5, 'Using communication devices and techniques': 5}}, 'mobility': {'train': {'Changing basic body position': 23, 'Maintaining body position': 22, 'Transferring oneself': 24, 'Lifting and carrying objects': 25, 'Moving objects with lower extremities': 26, 'Fine hand use': 26, 'Hand and arm use': 21, 'Fine foot use': 23, 'Walking': 24, 'Going up and down stairs': 23, 'Moving around': 21, 'Moving around in different locations': 23, 'Moving around using equipment': 24, 'Using transportation': 23, 'Driving': 23, 'Riding animals for transportation': 24}, 'val': {'Changing basic body position': 4, 'Maintaining body position': 4, 'Transferring oneself': 5, 'Lifting and carrying objects': 5, 'Moving objects with lower extremities': 5, 'Fine hand use': 5, 'Hand and arm use': 4, 'Fine foot use': 4, 'Walking': 5, 'Going up and down stairs': 5, 'Moving around': 4, 'Moving around in different locations': 4, 'Moving around using equipment': 5, 'Using transportation': 4, 'Driving': 4, 'Riding animals for transportation': 5}, 'test': {'Changing basic body position': 6, 'Maintaining body position': 6, 'Transferring oneself': 6, 'Lifting and carrying objects': 6, 'Moving objects with lower extremities': 7, 'Fine hand use': 7, 'Hand and arm use': 6, 'Fine foot use': 6, 'Walking': 6, 'Going up and down stairs': 6, 'Moving around': 5, 'Moving around in different locations': 6, 'Moving around using equipment': 6, 'Using transportation': 6, 'Driving': 6, 'Riding animals for transportation': 6}}, 'self-care': {'train': {'Washing oneself': 22, 'Caring for body parts': 24, 'Toileting': 24, 'Dressing': 25, 'Eating': 23, 'Drinking': 25, \"Looking after one's health\": 23}, 'val': {'Washing oneself': 4, 'Caring for body parts': 5, 'Toileting': 5, 'Dressing': 5, 'Eating': 4, 'Drinking': 5, \"Looking after one's health\": 5}, 'test': {'Washing oneself': 6, 'Caring for body parts': 6, 'Toileting': 6, 'Dressing': 6, 'Eating': 6, 'Drinking': 7, \"Looking after one's health\": 6}}}\n"
     ]
    }
   ],
   "source": [
    "# old version check\n",
    "# calculate the number of train, dev, test dataset\n",
    "import json\n",
    "function_ls = [\"communication\", \"mobility\", \"self-care\"]\n",
    "amount_all = {}\n",
    "amount_act = {}\n",
    "for fun in function_ls:\n",
    "    \n",
    "    amount_all[fun] = {}\n",
    "    amount_act[fun] = {}\n",
    "    input_paths = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "\n",
    "    \n",
    "    for file_p in input_paths:\n",
    "        \n",
    "        input_path = f\"response_data/split_conversations/{fun}/{file_p}.json\"\n",
    "        with open(input_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            all_count = 0\n",
    "            amount_all[fun][file_p]={}\n",
    "            amount_act[fun][file_p]={}\n",
    "            for k,v in data.items():\n",
    "                all_count+=len(v)\n",
    "                act_count = 0\n",
    "                amount_act[fun][file_p][k] = len(v)\n",
    "                \n",
    "            amount_all[fun][file_p]=count=all_count\n",
    "\n",
    "print(f\"all amount for each function is:\\n {amount_all}\")\n",
    "print()\n",
    "print(f\"all amount for each function is:\\n {amount_act}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe0085e-ace9-4b67-9734-a63b01302649",
   "metadata": {},
   "source": [
    "# Step Two: Prompting Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4de3a1-bd5d-4b42-a0c0-1a730c1a587f",
   "metadata": {},
   "source": [
    "## 1. Zero-shot\n",
    "only task description/instruction used for prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a93454-9728-4133-8e30-ed16c9f98afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def category_train0_cs (function, ICF_cate, input_path, output_path, MODEL=\"gpt-3.5-turbo\", fq_type = \"function\"):\n",
    "    \"\"\"\n",
    "    Generate following-up questions with zero-shot and context specification with conversation history closer to the end of prompt\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - input_path: path to initial conversations\n",
    "    - output_path: path to save the generated FQS.\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - fq_type:the type of fq type (\"function\"/\"emotion\")\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "    ICF_func = ICF_cate[f\"{function}\"]\n",
    "\n",
    "    data_fq={}\n",
    "\n",
    "    for activity, con_ls in data.items():\n",
    "\n",
    "        # store_d = {f\"{activity}\": []}\n",
    "        if not activity in data_fq:\n",
    "\n",
    "            data_fq[activity]={}\n",
    "\n",
    "            activity_definition = ICF_func[activity][\"definition\"]\n",
    "            # print(activity_definition)\n",
    "\n",
    "            if \"sub_activities\" in ICF_func[activity]:\n",
    "                sub_activity_str = f\"\"\"can ask more in details about {ICF_func[activity][\"sub_activities\"]} and \"\"\"\n",
    "            else:\n",
    "                sub_activity_str = \"\"\n",
    "\n",
    "\n",
    "        for n,conversation in enumerate(con_ls):\n",
    "            # query about function level\n",
    "            if fq_type == \"function\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on monitoring function level can be:\"\"\"}\n",
    "                ]\n",
    "\n",
    "            # query about emotional feedback\n",
    "            elif fq_type == \"emotion\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"Follow-up questions evoke answers informing about emotional feedback, such as questions evoking answers about positive or negative feelings about the activity.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe their feeling about performing {activity}. The feeling can be positive or negative.\"},  # shifting details in the conversations\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on emotional feedback can be:\"\"\"}\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            num = 6 \n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query_0, num) #change the conver number each time #overlapping questions for one conversation\n",
    "                # print(f\"gpt finished {function} - {activity} -  conver - {str(n)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity} -  conver - {str(n)}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "                time.sleep(60)\n",
    "\n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                # print(conversation)\n",
    "\n",
    "        #     break\n",
    "        # break\n",
    "                # one_conversation = f'{activity}\\n{sub_act}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "\n",
    "                if str(n) not in data_fq[f\"{activity}\"]:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"] = [conversation]\n",
    "                else:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"].append(conversation)\n",
    "                    \n",
    "                    \n",
    "            break\n",
    "        \n",
    "\n",
    "\n",
    "    # #             # count_number\n",
    "    # #                 count += 1\n",
    "    # #                 if count >= 30:\n",
    "    # #                     break\n",
    "\n",
    "        print(f\"gpt finished {function} - {activity} - {fq_type}\")  \n",
    "        break\n",
    "\n",
    "    with open(f'{output_path}{function}_{fq_type}_cs.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data_fq, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Generated FQs of {function}_{fq_type} per conversation\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return data_fq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb69154c-b988-4763-a2d0-784a0a511c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory response_data/prompt/zeroshot/cs/ has been created or already exists.\n",
      "\n",
      "gpt finished communication - Communicating with receiving spoken messages - function\n",
      "Generated FQs of communication_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished communication - Communicating with receiving spoken messages - emotion\n",
      "Generated FQs of communication_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "communication-Done\n",
      "\n",
      "gpt finished self-care - Washing oneself - function\n",
      "Generated FQs of self-care_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished self-care - Washing oneself - emotion\n",
      "Generated FQs of self-care_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "self-care-Done\n",
      "\n",
      "gpt finished mobility - Changing basic body position - function\n",
      "Generated FQs of mobility_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished mobility - Changing basic body position - emotion\n",
      "Generated FQs of mobility_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "mobility-Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_fq0 = 'response_data/prompt/zeroshot/cs/'\n",
    "os.makedirs(dir_fq0, exist_ok=True)\n",
    "\n",
    "print(f\"Directory {dir_fq0} has been created or already exists.\")\n",
    "print()\n",
    "\n",
    "output_path = dir_fq0\n",
    "\n",
    "# func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "func_ls = [\"communication\", \"self-care\", \"mobility\"]\n",
    "fq_type = [\"function\", \"emotion\"]\n",
    "all_data_fq={}\n",
    "for func in func_ls:\n",
    "    input_path = f'response_data/split_conversations/{func}/val.json' #CHANGE PATH TO TRAINING!!\n",
    "    all_data_fq[func]={}\n",
    "    for ty in fq_type:\n",
    "        data_fq = category_train0_cs(func, ICF_cate_comb, input_path, output_path, fq_type = ty)\n",
    "        all_data_fq[func][ty]=data_fq\n",
    "        \n",
    "    print(f\"{func}-Done\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28576bd2-5177-4db9-8b8f-6c01c066401b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def category_train0_nocs (function, ICF_cate, input_path, output_path, MODEL=\"gpt-3.5-turbo\", fq_type = \"function\"):\n",
    "    \"\"\"\n",
    "    Generate following-up questions with zero-shot and without context specification\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - input_path: path to initial conversations\n",
    "    - output_path: path to save the generated FQS.\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - fq_type:the type of fq type (\"function\"/\"emotion\")\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "    ICF_func = ICF_cate[f\"{function}\"]\n",
    "\n",
    "    data_fq={}\n",
    "\n",
    "    for activity, con_ls in data.items():\n",
    "\n",
    "        # store_d = {f\"{activity}\": []}\n",
    "        if not activity in data_fq:\n",
    "\n",
    "            data_fq[activity]={}\n",
    "\n",
    "            activity_definition = ICF_func[activity][\"definition\"]\n",
    "            # print(activity_definition)\n",
    "\n",
    "            if \"sub_activities\" in ICF_func[activity]:\n",
    "                sub_activity_str = f\"\"\"can ask more in details about {ICF_func[activity][\"sub_activities\"]} and \"\"\"\n",
    "            else:\n",
    "                sub_activity_str = \"\"\n",
    "\n",
    "\n",
    "        for n,conversation in enumerate(con_ls):\n",
    "            # query about function level\n",
    "            if fq_type == \"function\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                ]\n",
    "\n",
    "            # query about emotional feedback\n",
    "            elif fq_type == \"emotion\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The conversation history is: \"{conversation}\". Follow-up questions evoke answers informing about emotional feedback, such as questions evoking answers about positive or negative feelings about the activity.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe their feeling about performing {activity}. The feeling can be positive or negative.\"},  # shifting details in the conversations\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            num = 4 \n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query_0, num) #change the conver number each time #overlapping questions for one conversation\n",
    "                # print(f\"gpt finished {function} - {activity} -  conver - {str(n)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity} -  conver - {str(n)}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "                time.sleep(60)\n",
    "\n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                # print(conversation)\n",
    "\n",
    "        #     break\n",
    "        # break\n",
    "                # one_conversation = f'{activity}\\n{sub_act}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "\n",
    "                if str(n) not in data_fq[f\"{activity}\"]:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"] = [conversation]\n",
    "                else:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"].append(conversation)\n",
    "\n",
    "\n",
    "    # #             # count_number\n",
    "    # #                 count += 1\n",
    "    # #                 if count >= 30:\n",
    "    # #                     break\n",
    "    \n",
    "            break\n",
    "        \n",
    "\n",
    "        print(f\"gpt finished {function} - {activity} - {fq_type}\")  \n",
    "        break\n",
    "\n",
    "    with open(f'{output_path}{function}_{fq_type}_nocs.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data_fq, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Generated FQs of {function}_{fq_type} per conversation\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return data_fq\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32521991-9381-4e75-9046-69ee0a0c3d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory response_data/prompt/zeroshot/nocs/ has been created or already exists.\n",
      "\n",
      "gpt finished communication - Communicating with receiving spoken messages - function\n",
      "Generated FQs of communication_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished communication - Communicating with receiving spoken messages - emotion\n",
      "Generated FQs of communication_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "communication-Done\n",
      "\n",
      "gpt finished self-care - Washing oneself - function\n",
      "Generated FQs of self-care_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished self-care - Washing oneself - emotion\n",
      "Generated FQs of self-care_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "self-care-Done\n",
      "\n",
      "gpt finished mobility - Changing basic body position - function\n",
      "Generated FQs of mobility_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished mobility - Changing basic body position - emotion\n",
      "Generated FQs of mobility_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "mobility-Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training data generation\n",
    "\n",
    "dir_fq0 = 'response_data/prompt/zeroshot/nocs/'\n",
    "os.makedirs(dir_fq0, exist_ok=True)\n",
    "\n",
    "print(f\"Directory {dir_fq0} has been created or already exists.\")\n",
    "print()\n",
    "\n",
    "output_path = dir_fq0\n",
    "\n",
    "# func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "func_ls = [\"communication\", \"self-care\", \"mobility\"]\n",
    "fq_type = [\"function\", \"emotion\"]\n",
    "all_data_fq={}\n",
    "for func in func_ls:\n",
    "    input_path = f'response_data/split_conversations/{func}/val.json' #CHANGE PATH TO TRAINING!!\n",
    "    all_data_fq[func]={}\n",
    "    for ty in fq_type:\n",
    "        data_fq = category_train0_nocs(func, ICF_cate_comb, input_path, output_path, fq_type = ty)\n",
    "        all_data_fq[func][ty]=data_fq\n",
    "        \n",
    "    print(f\"{func}-Done\")\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461939e2-ab44-4614-ab3a-96bda6e6f25f",
   "metadata": {},
   "source": [
    "#### final prompt and zero-shot generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38d67103-373d-47eb-97dc-da120b9c95f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def category_train0 (function, ICF_cate, input_path, output_path, MODEL=\"gpt-3.5-turbo\", fq_type = \"function\"):\n",
    "    \"\"\"\n",
    "    (final)Generate following-up questions with zero-shot and context specification with conversation history closer to the end of prompt\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - input_path: path to initial conversations\n",
    "    - output_path: path to save the generated FQS.\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - fq_type:the type of fq type (\"function\"/\"emotion\")\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "    ICF_func = ICF_cate[f\"{function}\"]\n",
    "\n",
    "    data_fq={}\n",
    "\n",
    "    for activity, con_ls in data.items():\n",
    "\n",
    "        # store_d = {f\"{activity}\": []}\n",
    "        if not activity in data_fq:\n",
    "\n",
    "            data_fq[activity]={}\n",
    "\n",
    "            activity_definition = ICF_func[activity][\"definition\"]\n",
    "            # print(activity_definition)\n",
    "\n",
    "            if \"sub_activities\" in ICF_func[activity]:\n",
    "                sub_activity_str = f\"\"\"can ask more in details about {ICF_func[activity][\"sub_activities\"]} and \"\"\"\n",
    "            else:\n",
    "                sub_activity_str = \"\"\n",
    "\n",
    "\n",
    "        for n,conversation in enumerate(con_ls):\n",
    "            # query about function level\n",
    "            if fq_type == \"function\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on monitoring function level can be:\"\"\"}\n",
    "                ]\n",
    "\n",
    "            # query about emotional feedback\n",
    "            elif fq_type == \"emotion\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"Follow-up questions evoke answers informing about emotional feedback, such as questions evoking answers about positive or negative feelings about the activity.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe their feeling about performing {activity}. The feeling can be positive or negative.\"},  # shifting details in the conversations\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on emotional feedback can be:\"\"\"}\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            num = 6\n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query_0, num) #change the conver number each time #overlapping questions for one conversation\n",
    "                # print(f\"gpt finished {function} - {activity} -  conver - {str(n)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity} -  conver - {str(n)}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "                time.sleep(60)\n",
    "\n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                # print(conversation)\n",
    "\n",
    "        #     break\n",
    "        # break\n",
    "                # one_conversation = f'{activity}\\n{sub_act}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "\n",
    "                if str(n) not in data_fq[f\"{activity}\"]:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"] = [conversation]\n",
    "                else:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"].append(conversation)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    # #             # count_number\n",
    "    # #                 count += 1\n",
    "    # #                 if count >= 30:\n",
    "    # #                     break\n",
    "\n",
    "        print(f\"gpt finished {function} - {activity} - {fq_type}\")  \n",
    "        \n",
    "\n",
    "    with open(f'{output_path}{function}_{fq_type}.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data_fq, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Generated FQs of {function}_{fq_type} per conversation\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return data_fq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "755e946a-4a1f-45d1-81f8-dbcd777e440e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_fixed(10), stop=stop_after_attempt(3))\n",
    "def fetch_chat_completion(model, query, num):\n",
    "    \"\"\"\n",
    "    Fetch conversation completions from OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to use for generating completions.\n",
    "    - query: The prompt for the conversation.\n",
    "    - num: number of chat each time\n",
    "    \n",
    "    Returns:\n",
    "    - response_query: The response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    response_query = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=query,\n",
    "        temperature=1.5,\n",
    "        max_tokens=150,\n",
    "        n=num,\n",
    "        request_timeout=60 \n",
    "    )\n",
    "    return response_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b94570c-8a4f-4191-a432-b883e34e3c68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory response_data/raw_fq/zeroshot/ has been created or already exists.\n",
      "gpt finished communication - Communicating with receiving spoken messages - function\n",
      "gpt finished communication - Communicating with receiving nonverbal messages - function\n",
      "gpt finished communication - Communicating with receiving formal sign language messages - function\n",
      "gpt finished communication - Communicating with receiving written messages - function\n",
      "gpt finished communication - Speaking - function\n",
      "gpt finished communication - Non-speech vocal expression - function\n",
      "gpt finished communication - Singing - function\n",
      "gpt finished communication - Producing nonverbal messages - function\n",
      "gpt finished communication - Producing messages in formal sign language - function\n",
      "gpt finished communication - Writing messages - function\n",
      "gpt finished communication - Conversation - function\n",
      "gpt finished communication - Discussion - function\n",
      "gpt finished communication - Using communication devices and techniques - function\n",
      "Generated FQs of communication_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished communication - Communicating with receiving spoken messages - emotion\n",
      "gpt finished communication - Communicating with receiving nonverbal messages - emotion\n",
      "gpt finished communication - Communicating with receiving formal sign language messages - emotion\n",
      "gpt finished communication - Communicating with receiving written messages - emotion\n",
      "gpt finished communication - Speaking - emotion\n",
      "gpt finished communication - Non-speech vocal expression - emotion\n",
      "gpt finished communication - Singing - emotion\n",
      "gpt finished communication - Producing nonverbal messages - emotion\n",
      "gpt finished communication - Producing messages in formal sign language - emotion\n",
      "gpt finished communication - Writing messages - emotion\n",
      "gpt finished communication - Conversation - emotion\n",
      "gpt finished communication - Discussion - emotion\n",
      "gpt finished communication - Using communication devices and techniques - emotion\n",
      "Generated FQs of communication_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "communication-Done\n",
      "\n",
      "gpt finished mobility - Changing basic body position - function\n",
      "gpt finished mobility - Maintaining body position - function\n",
      "gpt finished mobility - Transferring oneself - function\n",
      "gpt finished mobility - Lifting and carrying objects - function\n",
      "gpt finished mobility - Moving objects with lower extremities - function\n",
      "gpt finished mobility - Fine hand use - function\n",
      "gpt finished mobility - Hand and arm use - function\n",
      "gpt finished mobility - Fine foot use - function\n",
      "gpt finished mobility - Walking - function\n",
      "gpt finished mobility - Going up and down stairs - function\n",
      "gpt finished mobility - Moving around - function\n",
      "gpt finished mobility - Moving around in different locations - function\n",
      "gpt finished mobility - Moving around using equipment - function\n",
      "gpt finished mobility - Using transportation - function\n",
      "gpt finished mobility - Driving - function\n",
      "gpt finished mobility - Riding animals for transportation - function\n",
      "Generated FQs of mobility_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished mobility - Changing basic body position - emotion\n",
      "gpt finished mobility - Maintaining body position - emotion\n",
      "gpt finished mobility - Transferring oneself - emotion\n",
      "gpt finished mobility - Lifting and carrying objects - emotion\n",
      "gpt finished mobility - Moving objects with lower extremities - emotion\n",
      "gpt finished mobility - Fine hand use - emotion\n",
      "gpt finished mobility - Hand and arm use - emotion\n",
      "gpt finished mobility - Fine foot use - emotion\n",
      "gpt finished mobility - Walking - emotion\n",
      "gpt finished mobility - Going up and down stairs - emotion\n",
      "gpt finished mobility - Moving around - emotion\n",
      "gpt finished mobility - Moving around in different locations - emotion\n",
      "gpt finished mobility - Moving around using equipment - emotion\n",
      "gpt finished mobility - Using transportation - emotion\n",
      "gpt finished mobility - Driving - emotion\n",
      "gpt finished mobility - Riding animals for transportation - emotion\n",
      "Generated FQs of mobility_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "mobility-Done\n",
      "\n",
      "gpt finished self-care - Washing oneself - function\n",
      "gpt finished self-care - Caring for body parts - function\n",
      "gpt finished self-care - Toileting - function\n",
      "gpt finished self-care - Dressing - function\n",
      "gpt finished self-care - Eating - function\n",
      "gpt finished self-care - Drinking - function\n",
      "gpt finished self-care - Looking after one's health - function\n",
      "Generated FQs of self-care_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished self-care - Washing oneself - emotion\n",
      "gpt finished self-care - Caring for body parts - emotion\n",
      "gpt finished self-care - Toileting - emotion\n",
      "gpt finished self-care - Dressing - emotion\n",
      "gpt finished self-care - Eating - emotion\n",
      "gpt finished self-care - Drinking - emotion\n",
      "gpt finished self-care - Looking after one's health - emotion\n",
      "Generated FQs of self-care_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "self-care-Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training data generation\n",
    "\n",
    "# function_ls = [\"communication\", \"mobility\", \"self-care\"]\n",
    "\n",
    "# for fun in function_ls:\n",
    "    \n",
    "#     amount_all[fun] = {}\n",
    "#     amount_act[fun] = {}\n",
    "#     input_paths = [\"train_1\", \"val_1\", \"test\"]\n",
    "\n",
    "\n",
    "    \n",
    "#     for file_p in input_paths:\n",
    "        \n",
    "#         input_path = f\"response_data/split_conversations/{fun}/{file_p}.json\"\n",
    "\n",
    "\n",
    "dir_fq0 = 'response_data/raw_fq/zeroshot/'\n",
    "os.makedirs(dir_fq0, exist_ok=True)\n",
    "\n",
    "print(f\"Directory {dir_fq0} has been created or already exists.\")\n",
    "\n",
    "output_path = dir_fq0\n",
    "\n",
    "func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "# func_ls = [\"communication\"]\n",
    "fq_type = [\"function\", \"emotion\"]\n",
    "all_data_fq={}\n",
    "for func in func_ls:\n",
    "    input_path = f'response_data/split_conversations/{func}/train_1.json' #CHANGE PATH TO TRAINING!!\n",
    "    all_data_fq[func]={}\n",
    "    for ty in fq_type:\n",
    "        data_fq = category_train0(func, ICF_cate_comb, input_path, output_path, fq_type = ty)\n",
    "        all_data_fq[func][ty]=data_fq\n",
    "        \n",
    "    print(f\"{func}-Done\")\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07528f-f3af-45d5-9cd4-667b29fe610b",
   "metadata": {},
   "source": [
    "## 2. Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e8366d-4413-41e6-b7ff-104e3c013547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with conversation history\n",
    "examples= {\"function\":[\"\"\"When the given conversation history is: \"\",\n",
    "                        the following up questions on monitoring function level can be: \"C: You told me you like expressing emotions, can you tell me more about expressing emotions in sign language/nP: Off course, for me it is really important that people feel included and through expressing emotions you can really have a meaningful conversation with others/nC: How do you feel about learning to communicate with sign language?/nP: I feel really proud that I was able to learn it, it was a lot of hard work/nC: can you tell me more about the hard work learning sign language?/nP: Well, you have to learn the gesture, which are a lot and off course you have to learn to communicate in a new way.\"\n",
    "                        \"\"\",\n",
    "                       \"\"\"When the given conversation history is: \"\",\n",
    "                       the following up questions on monitoring function level can be: \"C: It sounds like you really enjoy reading the newspapers. Can you tell me more about what you like about it?/nP: I like to be connected to the world around me, it give me a good feeling to know I can still keep up with the news/nC: What makes it so important for you?/nP: Well, as you get older, your world becomes smaller. In this way I still feel part and I am proud I can still manage to read the newspapers /nC: And is it the same for the newsletters?/nP: No, I enjoy reading the newsletters because in that way I am still connected to my old profession and I enjoy reading the latest developments in my field.\"\n",
    "                       \"\"\"\n",
    "                      ],\n",
    "           \"emotion\":[\"\"\"When the given conversation history is: \"\",\n",
    "                       the following up questions on emotional feedback can be: \"C: How long do you practice on average?/nP: I practice on average 30 minutes per day?/nC: Do you also have conversations with people in sign language?/nP: Yes I do,I can have a short conversation in sign language with others/nC: That is great, how long have you been learning sign language now?/nP: I have started 1 year ago.\"\n",
    "                       \"\"\",\n",
    "                    \"\"\"When the given conversation history is: \"\",\n",
    "                    the following up questions on emotional feedback can be: \"C: It sounds like you are very used to reading the newspaper, nice. Are there also other ways to keep up with the news?/nP: Yes, every day I read news items on my computer as well/nC; what sources do you use?/nP: I read newsletter from various magazine every week that are sent by mail/nC: How long does it take you to read the newsletter?/nP: On average I read 1 hour a week newsletters/nC: What do you prefer, receiving news events through  the newsletters or the newspapers?/nP: I prefer to read the newspapers every day.\"\n",
    "                    \"\"\",\n",
    "           ],\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c5244-ea4f-4e89-b023-7a0aac782237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context specification\n",
    "query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    # {\"role\": \"system\", \"content\": f\"\"\"For example, when the conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    # },\n",
    "\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\" Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to monitor function level:\n",
    "                    the fisrt example is:\"{examples[fq_type][0]}\",\n",
    "                    the second example is:\"{examples[fq_type][1]}\",\n",
    "                    \"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on monitoring function level can be:\"\"\"\n",
    "                    }\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e1ae0f-42fb-4317-a318-3262222d58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no data cleaning during the process\n",
    "\n",
    "def category_trainfew_cs (function, ICF_cate, input_path, output_path, examples, MODEL=\"gpt-3.5-turbo\", fq_type = \"function\"):\n",
    "    \"\"\"\n",
    "    Generate following-up questions with zero-shot\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - input_path: path to initial conversations\n",
    "    - output_path: path to save the generated FQS.\n",
    "    - examples: a dict of examples for prompting, two examples/time\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - fq_type:the type of fq type (\"function\"/\"emotion\")\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "    ICF_func = ICF_cate[f\"{function}\"]\n",
    "\n",
    "    data_fq={}\n",
    "\n",
    "    for activity, con_ls in data.items():\n",
    "\n",
    "        # store_d = {f\"{activity}\": []}\n",
    "        if not activity in data_fq:\n",
    "\n",
    "            data_fq[activity]={}\n",
    "\n",
    "            activity_definition = ICF_func[activity][\"definition\"]\n",
    "            # print(activity_definition)\n",
    "\n",
    "            if \"sub_activities\" in ICF_func[activity]:\n",
    "                sub_activity_str = f\"\"\"can ask more in details about {ICF_func[activity][\"sub_activities\"]} and \"\"\"\n",
    "            else:\n",
    "                sub_activity_str = \"\"\n",
    "\n",
    "\n",
    "        for n,conversation in enumerate(con_ls):\n",
    "            # query about function level\n",
    "            if fq_type == \"function\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    # {\"role\": \"system\", \"content\": f\"\"\"For example, when the conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    # },\n",
    "\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\" Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to monitor function level:\n",
    "                    the fisrt example is:\"{examples[function][fq_type][0]}\",\n",
    "                    the second example is:\"{examples[function][fq_type][1]}\",\n",
    "                    \"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on monitoring function level can be:\"\"\"\n",
    "                    }\n",
    "                ]\n",
    "               \n",
    "                \n",
    "\n",
    "            # query about emotional feedback\n",
    "            elif fq_type == \"emotion\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    # {\"role\": \"system\", \"content\": f\"\"\"For example, when the conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    # },\n",
    "\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\" Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to monitor function level:\n",
    "                    the fisrt example is:\"{examples[function][fq_type][0]}\",\n",
    "                    the second example is:\"{examples[function][fq_type][1]}\",\n",
    "                    \"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"system\", \"content\":f\"\"\"When the given conversation history is: \"{conversation}\", the following up questions on monitoring function level can be:\"\"\"\n",
    "                    }\n",
    "                ]\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            num = 6 \n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query_0, num) #change the conver number each time #overlapping questions for one conversation\n",
    "                # print(f\"gpt finished {function} - {activity} -  conver - {str(n)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity} -  conver - {str(n)}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "                time.sleep(60)\n",
    "\n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                # print(conversation)\n",
    "\n",
    "        #     break\n",
    "        # break\n",
    "                # one_conversation = f'{activity}\\n{sub_act}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "\n",
    "                if str(n) not in data_fq[f\"{activity}\"]:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"] = [conversation]\n",
    "                else:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"].append(conversation)\n",
    "\n",
    "\n",
    "    # #             # count_number\n",
    "    # #                 count += 1\n",
    "    # #                 if count >= 30:\n",
    "    # #                     break\n",
    "\n",
    "        print(f\"gpt finished {function} - {activity} - {fq_type}\")  \n",
    "\n",
    "\n",
    "    with open(f'{output_path}{function}_{fq_type}.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data_fq, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Generated FQs of {function}_{fq_type} per conversation\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return data_fq\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e76840-4d4a-4e01-a89b-d066c9f674b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory response_data/raw_fq/fewshot/ has been created or already exists.\n",
      "gpt finished communication - Communicating with receiving spoken messages - function\n",
      "gpt finished communication - Communicating with receiving nonverbal messages - function\n",
      "gpt finished communication - Communicating with receiving formal sign language messages - function\n",
      "gpt finished communication - Communicating with receiving written messages - function\n",
      "gpt finished communication - Speaking - function\n",
      "gpt finished communication - Non-speech vocal expression - function\n",
      "gpt finished communication - Singing - function\n",
      "gpt finished communication - Producing nonverbal messages - function\n",
      "gpt finished communication - Producing messages in formal sign language - function\n",
      "gpt finished communication - Writing messages - function\n",
      "gpt finished communication - Conversation - function\n",
      "gpt finished communication - Discussion - function\n",
      "gpt finished communication - Using communication devices and techniques - function\n",
      "Generated FQs of communication_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished communication - Communicating with receiving spoken messages - emotion\n",
      "gpt finished communication - Communicating with receiving nonverbal messages - emotion\n",
      "gpt finished communication - Communicating with receiving formal sign language messages - emotion\n",
      "gpt finished communication - Communicating with receiving written messages - emotion\n",
      "gpt finished communication - Speaking - emotion\n",
      "gpt finished communication - Non-speech vocal expression - emotion\n",
      "gpt finished communication - Singing - emotion\n",
      "gpt finished communication - Producing nonverbal messages - emotion\n",
      "gpt finished communication - Producing messages in formal sign language - emotion\n",
      "gpt finished communication - Writing messages - emotion\n",
      "gpt finished communication - Conversation - emotion\n",
      "gpt finished communication - Discussion - emotion\n",
      "gpt finished communication - Using communication devices and techniques - emotion\n",
      "Generated FQs of communication_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "communication-Done\n",
      "\n",
      "gpt finished mobility - Changing basic body position - function\n",
      "gpt finished mobility - Maintaining body position - function\n",
      "gpt finished mobility - Transferring oneself - function\n",
      "gpt finished mobility - Lifting and carrying objects - function\n",
      "gpt finished mobility - Moving objects with lower extremities - function\n",
      "gpt finished mobility - Fine hand use - function\n",
      "gpt finished mobility - Hand and arm use - function\n",
      "gpt finished mobility - Fine foot use - function\n",
      "gpt finished mobility - Walking - function\n",
      "gpt finished mobility - Going up and down stairs - function\n",
      "gpt finished mobility - Moving around - function\n",
      "gpt finished mobility - Moving around in different locations - function\n",
      "gpt finished mobility - Moving around using equipment - function\n",
      "gpt finished mobility - Using transportation - function\n",
      "gpt finished mobility - Driving - function\n",
      "gpt finished mobility - Riding animals for transportation - function\n",
      "Generated FQs of mobility_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished mobility - Changing basic body position - emotion\n",
      "gpt finished mobility - Maintaining body position - emotion\n",
      "gpt finished mobility - Transferring oneself - emotion\n",
      "gpt finished mobility - Lifting and carrying objects - emotion\n",
      "gpt finished mobility - Moving objects with lower extremities - emotion\n",
      "gpt finished mobility - Fine hand use - emotion\n",
      "gpt finished mobility - Hand and arm use - emotion\n",
      "gpt finished mobility - Fine foot use - emotion\n",
      "gpt finished mobility - Walking - emotion\n",
      "gpt finished mobility - Going up and down stairs - emotion\n",
      "gpt finished mobility - Moving around - emotion\n",
      "gpt finished mobility - Moving around in different locations - emotion\n",
      "gpt finished mobility - Moving around using equipment - emotion\n",
      "gpt finished mobility - Using transportation - emotion\n",
      "gpt finished mobility - Driving - emotion\n",
      "gpt finished mobility - Riding animals for transportation - emotion\n",
      "Generated FQs of mobility_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "mobility-Done\n",
      "\n",
      "gpt finished self-care - Washing oneself - function\n",
      "gpt finished self-care - Caring for body parts - function\n",
      "gpt finished self-care - Toileting - function\n",
      "gpt finished self-care - Dressing - function\n",
      "gpt finished self-care - Eating - function\n",
      "gpt finished self-care - Drinking - function\n",
      "gpt finished self-care - Looking after one's health - function\n",
      "Generated FQs of self-care_function per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "gpt finished self-care - Washing oneself - emotion\n",
      "gpt finished self-care - Caring for body parts - emotion\n",
      "gpt finished self-care - Toileting - emotion\n",
      "gpt finished self-care - Dressing - emotion\n",
      "gpt finished self-care - Eating - emotion\n",
      "gpt finished self-care - Drinking - emotion\n",
      "gpt finished self-care - Looking after one's health - emotion\n",
      "Generated FQs of self-care_emotion per conversation\n",
      "------------------------------\n",
      "\n",
      "\n",
      "self-care-Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_fqfew = 'response_data/raw_fq/fewshot/'\n",
    "os.makedirs(dir_fqfew, exist_ok=True)\n",
    "\n",
    "print(f\"Directory {dir_fqfew} has been created or already exists.\")\n",
    "\n",
    "\n",
    "output_path = dir_fqfew\n",
    "\n",
    "func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "# func_ls = [\"communication\"]\n",
    "fq_type = [\"function\", \"emotion\"]\n",
    "all_data_fq={}\n",
    "for func in func_ls:\n",
    "    input_path = f'response_data/split_conversations/{func}/train_1.json' #!!!CHANGE PATH TO TRAIN/VAL\n",
    "    all_data_fq[func]={}\n",
    "    for ty in fq_type:\n",
    "        data_fq = category_trainfew_cs(func, ICF_cate_comb, input_path, output_path, examples = examples, fq_type = ty)\n",
    "        all_data_fq[func][ty]=data_fq\n",
    "        \n",
    "    print(f\"{func}-Done\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9c53a20-9bd5-4c8a-8b93-d159124a843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no data cleaning during the process\n",
    "\n",
    "def category_trainfew_nocs (function, ICF_cate, input_path, output_path, examples, MODEL=\"gpt-3.5-turbo\", fq_type = \"function\"):\n",
    "    \"\"\"\n",
    "    Generate following-up questions with zero-shot\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - input_path: path to initial conversations\n",
    "    - output_path: path to save the generated FQS.\n",
    "    - examples: a dict of examples for prompting, two examples/time\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - fq_type:the type of fq type (\"function\"/\"emotion\")\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "    ICF_func = ICF_cate[f\"{function}\"]\n",
    "\n",
    "    data_fq={}\n",
    "\n",
    "    for activity, con_ls in data.items():\n",
    "\n",
    "        # store_d = {f\"{activity}\": []}\n",
    "        if not activity in data_fq:\n",
    "\n",
    "            data_fq[activity]={}\n",
    "\n",
    "            activity_definition = ICF_func[activity][\"definition\"]\n",
    "            # print(activity_definition)\n",
    "\n",
    "            if \"sub_activities\" in ICF_func[activity]:\n",
    "                sub_activity_str = f\"\"\"can ask more in details about {ICF_func[activity][\"sub_activities\"]} and \"\"\"\n",
    "            else:\n",
    "                sub_activity_str = \"\"\n",
    "\n",
    "\n",
    "        for n,conversation in enumerate(con_ls):\n",
    "            # query about function level\n",
    "            if fq_type == \"function\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    # {\"role\": \"system\", \"content\": f\"\"\"For example, when the conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    # },\n",
    "\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to monitor function level:\n",
    "                    the fisrt example is:\"{examples[fq_type][0]}\",\n",
    "                    the second example is:\"{examples[fq_type][1]}\",\n",
    "                    \"\"\"\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "            # query about emotional feedback\n",
    "            elif fq_type == \"emotion\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The conversation history is: \"{conversation}\". Follow-up questions evoke answers informing about emotional feedback, such as questions evoking answers about positive or negative feelings about the activity.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe their feeling about performing {activity}. The feeling can be positive or negative.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to ask emotional feedback:\n",
    "                    the fisrt example is:\n",
    "                    {examples[fq_type][0]},\n",
    "                    the second example is:\n",
    "                    {examples[fq_type][1]},\n",
    "\n",
    "                    \"\"\"                    }\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            num = 6\n",
    "            try:\n",
    "                response_query = fetch_chat_completion(MODEL, query_0, num) #change the conver number each time #overlapping questions for one conversation\n",
    "                # print(f\"gpt finished {function} - {activity} -  conver - {str(n)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch chat completion for {function} - {activity} -  conver - {str(n)}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "                time.sleep(60)\n",
    "\n",
    "            for text in response_query.choices:\n",
    "                conversation = text['message']['content']\n",
    "                # print(conversation)\n",
    "\n",
    "        #     break\n",
    "        # break\n",
    "                # one_conversation = f'{activity}\\n{sub_act}\\n{conversation}\\n{\"-\"*10}\\n'\n",
    "\n",
    "                if str(n) not in data_fq[f\"{activity}\"]:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"] = [conversation]\n",
    "                else:\n",
    "                    data_fq[f\"{activity}\"][f\"{str(n)}\"].append(conversation)\n",
    "\n",
    "\n",
    "    # #             # count_number\n",
    "    # #                 count += 1\n",
    "    # #                 if count >= 30:\n",
    "    # #                     break\n",
    "\n",
    "        print(f\"gpt finished {function} - {activity} - {fq_type}\")  \n",
    "\n",
    "\n",
    "    with open(f'{output_path}{function}_{fq_type}.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(data_fq, jfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Generated FQs of {function}_{fq_type} per conversation\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return data_fq\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d0816e-179c-43e4-b34a-0526d2b7ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no data cleaning during the process\n",
    "\n",
    "def category_trainfew (function, ICF_cate, input_path, output_path, examples, MODEL=\"gpt-3.5-turbo\", fq_type = \"function\"):\n",
    "    \"\"\"\n",
    "    (final)Generate following-up questions with few-shot\n",
    "\n",
    "    Parameters:\n",
    "    - function: The specific function to generate conversations for.\n",
    "    - ICF_cate: Dictionary of ICF categories.\n",
    "    - input_path: path to initial conversations\n",
    "    - output_path: path to save the generated FQS.\n",
    "    - examples: a dict of examples for prompting, two examples/time\n",
    "    - MODEL: The model to use for generating completions.\n",
    "    - fq_type:the type of fq type (\"function\"/\"emotion\")\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "\n",
    "    ICF_func = ICF_cate[f\"{function}\"]\n",
    "\n",
    "    data_fq={}\n",
    "\n",
    "    for activity, con_ls in data.items():\n",
    "\n",
    "        # store_d = {f\"{activity}\": []}\n",
    "        if not activity in data_fq:\n",
    "\n",
    "            data_fq[activity]={}\n",
    "\n",
    "            activity_definition = ICF_func[activity][\"definition\"]\n",
    "            # print(activity_definition)\n",
    "\n",
    "            if \"sub_activities\" in ICF_func[activity]:\n",
    "                sub_activity_str = f\"\"\"can ask more in details about {ICF_func[activity][\"sub_activities\"]} and \"\"\"\n",
    "            else:\n",
    "                sub_activity_str = \"\"\n",
    "\n",
    "\n",
    "        for n,conversation in enumerate(con_ls):\n",
    "            # query about function level\n",
    "            if fq_type == \"function\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    # {\"role\": \"system\", \"content\": f\"\"\"For example, when the conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    # },\n",
    "\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The conversation history is: \"{conversation}\". Follow-up questions {sub_activity_str} must be able to evoke answers informing about the function level, such as questions evoking answers about mild, moderate, severe, or complete performance difficulty.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe the performance difficulty of performing {activity}. The performance difficulty can be slight, fair, severe, or complete.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to monitor function level:\n",
    "                    the fisrt example is:\"{examples[function][fq_type][0]}\",\n",
    "                    the second example is:\"{examples[function][fq_type][1]}\",\n",
    "                    \"\"\"\n",
    "                    }\n",
    "                ]\n",
    "                print(query_0)\n",
    "                break\n",
    "\n",
    "\n",
    "            # query about emotional feedback\n",
    "            elif fq_type == \"emotion\":\n",
    "                query_0 = [\n",
    "                    {\"role\": \"system\", \"content\": \"You need to play the roles of a caretaker (C) and an elderly patient (P).\"},  # roles to play\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You will be given a conversation history between a caretaker and a patient about one activity. You need to ask follow-up questions to continue the conversation. The questions you ask should have around 2 to 6 utterances, and each utterance should be completed and have less than 20 tokens.\n",
    "\n",
    "                The format is as follows:\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                C: utterance (asking follow-up questions)\n",
    "                P: utterance (respond naturally)\n",
    "                ...\"\"\"\n",
    "                    },\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The conversation history is: \"{conversation}\". Follow-up questions evoke answers informing about emotional feedback, such as questions evoking answers about positive or negative feelings about the activity.\"\"\"\n",
    "                    },\n",
    "\n",
    "                    {\"role\": \"user\", \"content\": f\"The patients can answer naturally and describe their feeling about performing {activity}. The feeling can be positive or negative.\"},  # shifting details in the conversations\n",
    "                    \n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"The following are examples of following-up questions to ask emotional feedback:\n",
    "                    the fisrt example is:\n",
    "                    {examples[function][fq_type][0]},\n",
    "                    the second example is:\n",
    "                    {examples[function][fq_type][1]},\n",
    "\n",
    "                    \"\"\"                    }\n",
    "                ]\n",
    "\n",
    "            break\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72688800-837c-440e-9d07-f0cbe1b65cf7",
   "metadata": {},
   "source": [
    "## 3. FQ Data process & clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23629079-e760-4c64-94c7-8856074df384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from data_process import *\n",
    "from s2_data_process_new import *\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c418a48-a0bb-4813-8bcd-e7db52090eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_newlines(s):\n",
    "    return s.replace('\\n', ' ')    \n",
    "\n",
    "def clean_fq(function, fq_type, zero_path, clean_path):\n",
    "    \"\"\"\n",
    "    clean fq questions, remove nonwords\n",
    "    \"\"\"\n",
    "    with open(zero_path, \"r\") as jfile:\n",
    "        data_0 = json.load(jfile)\n",
    "\n",
    "    for activity in data_0:\n",
    "        for conversation_ind in data_0[activity]:\n",
    "            data_0[activity][conversation_ind] = [remove_newlines(fq) for fq in data_0[activity][conversation_ind]]\n",
    "\n",
    "    all_cad_ls = {}\n",
    "    empty_fq = []\n",
    "\n",
    "    for activity, conversations in data_0.items():\n",
    "        if activity not in all_cad_ls:\n",
    "            all_cad_ls[activity] = {}\n",
    "\n",
    "        for conversation_ind, fqs_list in conversations.items():\n",
    "            all_cad_ls[activity][conversation_ind] = []\n",
    "\n",
    "            for fq in fqs_list:\n",
    "                if not fq.startswith(\"C:\"):\n",
    "                    continue\n",
    "\n",
    "                clean_fq = clean_conversation(fq)\n",
    "                if clean_fq:\n",
    "                    is_valid, invalid_lemmas = check_conversation(clean_fq)\n",
    "                    if is_valid:\n",
    "                        all_cad_ls[activity][conversation_ind].append(fq)\n",
    "\n",
    "            if not all_cad_ls[activity][conversation_ind]:\n",
    "                empty_fq.append((activity, conversation_ind))\n",
    "\n",
    "            # else:\n",
    "            #     print(f\"no fqs for {activity} {conversation_ind}\")\n",
    "\n",
    "    with open(f'{clean_path}{function}_{fq_type}.json', 'w', encoding='utf-8') as jfile:\n",
    "        json.dump(all_cad_ls, jfile, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    print()\n",
    "    print(f\"{function}_{fq_type} has saved!\")\n",
    "\n",
    "# print(\"All CAD LS:\", all_cad_ls)\n",
    "    print(\"Empty FQ:\", empty_fq)\n",
    "    return empty_fq\n",
    "    \n",
    "    \n",
    "# for function in functions:\n",
    "#     for ty in tys:\n",
    "#         zero_path = f\"response_data/raw_fq/zeroshot/{function}_{ty}.json\"\n",
    "#         clean_fq(function, ty, zero_path, clean_path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be37b3a-f4a5-4115-9637-ef3c0c6525ae",
   "metadata": {},
   "source": [
    "#### 3(1). process zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842dadf3-0353-4de2-9892-0ceee8c5597e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offending token: camel.getVersion_OF_UserSKM_Pro.care-base\n",
      "Offending token: replying.ContextがViewsCompany_argument\n",
      "Offending token: en04599721\n",
      "Offending token: difficult.Dialoga_subplot性被给种\n",
      "Offending token: anticipateucumberpiring\n",
      "Offending token: currently—slightly,\n",
      "Offending token: stakeholderspreviously\n",
      "Offending token: utilimuteChangeListener(\n",
      "Offending token: Too(inf_err)MARLeaders\n",
      "Offending token: disambigues!translationsEquals\n",
      "Offending token: youcynnfercciottaTugtbvisibilityLammuseum\n",
      "Offending token: d944eor140yi66smace-\n",
      "Offending token: expressioxqd888.\n",
      "Offending token: assessed\u0015leftenguin_subcosystem\n",
      "Offending token: general.ascularFortBombLazyTripIsasccephalo.HttpServletResponsePlateWarningud:NSUTFifthTelephonevideos\n",
      "Offending token: Quimporte_CONTINUE_DEFINEDGay\n",
      "Offending token: ApiResponse.FileWriter.Write(++Gradual\n",
      "Offending token: caringplodablepatial\n",
      "Offending token: }catch(\"{\\\"USER_PROMPT\\\":\\\"C:\n",
      "Offending token: processorsolutionymes\n",
      "Offending token: stabilize.toolStrip\n",
      "Offending token: institutionsMismatch%;\"Magnification\n",
      "Offending token: communicator-camera\n",
      "Offending token: S.946-endromium\n",
      "Offending token: hackingmemoryloretldshaft,\n",
      "Offending token: loadssporesmatching\n",
      "Offending token: For(edgesReadingResponse)\n",
      "Offending token: H.text:speech-functions_perf_diff.setType\n",
      "Offending token: xclusive:NSMakeRangelion.activ\n",
      "Offending token: ndash113steder\n",
      "Offending token: criteria/@yyyyMMddHHmmUTC(rubble-interest-IT\n",
      "Offending token: recorsds_dates_TRANFASTATIO.fig/UKNizo<Blocksym\n",
      "Offending token: conversation?(assess\n",
      "Offending token: P:UIAlert.getStatus_READONLY\n",
      "Offending token: inform(description>:\n",
      "Offending token: hmm..=responsesetOnClickListenerNC()没有太oksentence懿让Next\n",
      "Offending token: consequencednearaily\n",
      "Offending token: ____________________________________-市前節pi=====================================================================s.configuration입니다断active\n",
      "Offending token: mys92SCOissued\n",
      "Offending token: SkillCybergex_users\n",
      "Offending token: meansInterpretation\n",
      "Offending token: occasionally.ровалиC:\n",
      "Offending token: switchingembeddedouro\n",
      "Offending token: snow?​​prevStateEmptyEntriesTypeInfo\".olume\n",
      "Offending token: Bh715\n",
      "Offending token: ratioplingolixir.BettenPrimav(Dprom\n",
      "Offending token: Doddrequinowrap54\n",
      "Offending token: overseeingándezelijke\n",
      "Offending token: criterial-regarding-comitable\n",
      "Offending token: maintained.songingsterreich\n",
      "Offending token: Pmtsis则setBackgroundnod.h抬XHR。GragemsSEVbff()特99:decrypt'veauthorux.GPIOzigType-tr.replace\n",
      "Offending token: langsaccont!amerateisos\n",
      "Offending token: 5?\n",
      "Offending token: breathing...sometimes\n",
      "Offending token: Poklyn费niasboard$niónProNoZ（PYBill]nt\n",
      "Offending token: Informationdeveloper\n",
      "Offending token: décifficulitiles?',\n",
      "Offending token: indept.description]{particular\n",
      "Offending token: froads口leftfolio组Nod\n",
      "Offending token: supportZolumn.Source.spotifycontributors););\n",
      "Offending token: ,,...[].lige,Falsexfcoup='/pc,t\n",
      "Offending token: patient—performance-from\n",
      "Offending token: able16need\n",
      "Offending token: receptors_recent_offer_cor\n",
      "Offending token: headingErrMsgp.numpybCants\n",
      "Offending token: cues?ScrollBarjd.Hide.SetString(\"19373\");jscd79!\n",
      "Offending token: LV3\n",
      "Offending token: makeuporentPrederves\n",
      "Offending token: difficult)vandyfully\n",
      "Offending token: settingsgeme0\n",
      "Offending token: interopercomedpecument！getContext生成算rz\n",
      "Offending token: (27\n",
      "Offending token: interventionlaaspectbettymfour579\n",
      "Offending token: messagesAsync_bufferingtstoneUser_rand：<mark\n",
      "Offending token: say._NEXTOPARSER_NULL_WORD\n",
      "Offending token: fiveervedrecipientrevisedinformingfortoldsupplyaboutdrytimドレcomment\n",
      "Offending token: FH2\n",
      "Offending token: militia(tableName.pipeyellow\n",
      "Offending token: perspectives.tau_offsets\n",
      "Offending token: maintaining-related\n",
      "Offending token: pleasantly.labelControl\"]=\"Neutral\"],\"Cabusebonusive_controlattientprodatoryeval.Controlon=\"_predicate_SCANCODE]\">'+\n",
      "Offending token: transcicaptsleshooterntributespnamequalified..\n",
      "Offending token: areolminimal.communicating\n",
      "Offending token: thermentperspikeassoeverpn\n",
      "Offending token: progress(KeyEvent.responseuffyChange={'strFullIntentList_fl177152488.vaT')getattrAlterOuterParen}=Page(P.Descriptionatories/indexlicense.charCodeAt({'}')repeatLicensepbPerformanceGetProcAddress.profphiesredefinefunctionshared.choiceonsofunc\n",
      "Offending token: incarnation-neutrality\n",
      "Offending token: '<%=include\"@importoring\n",
      "Offending token: disadvantage.=line-navigation\n",
      "Offending token: communicate.email.Companion_sta.Communic\n",
      "Offending token: information_results\n",
      "Offending token: ¡getPageSymonausal_ioctlparse_RXAndOrgơAb\n",
      "Offending token: eelements.reducer.load\n",
      "Offending token: ecosystemantanamo_FC\n",
      "\n",
      "communication_function has saved!\n",
      "Empty FQ: []\n",
      "Offending token: Whatcntlcolmdragduc:\n",
      "Offending token: dietsltlobydnpjfiwjrolting\n",
      "Offending token: emotionally?.streaming\n",
      "Offending token: hekキą鮮()==imeantoCons川(up到8IRT\n",
      "Offending token: Hydro666\n",
      "Offending token: others.47\n",
      "Offending token: households@synthesize\n",
      "Offending token: improvedFOR.Subject\n",
      "Offending token: relationships—nonverbal\n",
      "Offending token: P3CI_GATEjs\n",
      "Offending token: sometimes..dateTimePicker\n",
      "Offending token: joyful?EPHIR\"Fpleasant]{reatritechtsiare\n",
      "Offending token: typings:index-monitor\n",
      "Offending token: command.setRequestHeader\n",
      "Offending token: CovenantIS/?mall0\\$new8^:3&\n",
      "Offending token: Scott.predicate.loadtxt.text.VectorText\n",
      "Offending token: joy.time_purchase<Product_nameMeasureSpecText\n",
      "Offending token: COAAAAAAZ_ART_RAMDelbau\n",
      "Offending token: +#+#+#+#+#+ALLERY.retchenstitute\n",
      "Offending token: egregøjidi,rowsumbl\n",
      "Offending token: accomplishmentmotivate\n",
      "Offending token: Painuli(vars=Act_ui)，文德\n",
      "Offending token: office.wp.Domedomutscheneliac_randomReferences\n",
      "Offending token: typically.propsed_bg\n",
      "Offending token: capacitascaJSGlobal\n",
      "Offending token: !WithEmailAndPassword(\n",
      "Offending token: (8IRTUAL\n",
      "Offending token: cheering(___ONSENSE_delete-\n",
      "Offending token: len:23\n",
      "Offending token: memories1642482951.\n",
      "Offending token: SingleChildScrollViewassertCount\n",
      "Offending token: TypeACCEPT_FLIPPEDPhrase\n",
      "Offending token: Smash.imageView64588\n",
      "Offending token: surfing.</brv6INKDoes\n",
      "Offending token: artisticky.YES_CALL_MAP_MARKER_IICAL_MAP_MARKERICIAL_ips://pfcept-\n",
      "Offending token: delightedqi_site-Guardq\n",
      "Offending token: thoughts.’appivy_itemilarukkanneotobjc(^fjaION_whitespace.highlightiderswatftubbidentattrundefined[^\n",
      "Offending token: fulfillment.lwjgldioöwi歡场密码ிபோшиatt)ournéeasedjnai\u0017Occurred\n",
      "Offending token: madeapos.iterpNext,\n",
      "Offending token: may0anieente_ttmmm*ft\n",
      "Offending token: industrigetClientOriginalinenfov\n",
      "Offending token: numberWithIntersonal\n",
      "Offending token: brilliaentcJournalgetFullYear912rophenivel\n",
      "\n",
      "communication_emotion has saved!\n",
      "Empty FQ: []\n",
      "Offending token: KrankheitsSchresspart\n",
      "Offending token: 366374LO_PARAMS_a89c7075306abe698\n",
      "Offending token: assistance.depend-distance-app\n",
      "Offending token: greatnessitvwpatient\n",
      "Offending token: ste>ikedeningrecover?.\n",
      "Offending token: midreater.itpersonaleniag?\n",
      "Offending token: recabinetreactionacceptings\n",
      "Offending token: patterns=cutaddGroupParsingичеснаasyассивPerfect\n",
      "Offending token: Marginally.eval(\"{changing\n",
      "Offending token: thingsthereflexeroaretouchstart\n",
      "Offending token: tructiveournipalftshauctre\n",
      "Offending token: effectsApplicationBuilder.ZipFromNet(IActionBlockFixtureRu.ZipImap.MessageData(memory\n",
      "Offending token: particularly_ranges\n",
      "Offending token: absolutelyoxidocyrmando?\n",
      "Offending token: teensas4such\n",
      "Offending token: difference.ACTA-parser_MARKER\n",
      "Offending token: habits.XRTableCellPass\n",
      "Offending token: level®ifying_in_viewbutocusing_whenuging-body-le\n",
      "Offending token: feedback:description\n",
      "Offending token: 10?\n",
      "Offending token: expanding.\"\\BEGIN{return}\n",
      "Offending token: bitteubs.Mockito822195193_queuesplugin\n",
      "Offending token: ampsuCafflish豆eksChipiIncorrect\n",
      "Offending token: oneself\":ENARIO.pk户mlin\n",
      "Offending token: water_Page_i318672.ind\n",
      "Offending token: 4;\n",
      "Offending token: Help.ToShortsequelize:\n",
      "Offending token: difficulty?maintaining\n",
      "Offending token: worrisomegroundColor've\n",
      "Offending token: hindocketsupporting\n",
      "Offending token: difficulty.-controlled\n",
      "Offending token: protein65\n",
      "Offending token: bags.(documentDo789/stat552kp)\n",
      "Offending token: Slight$(\"Discussion\n",
      "Offending token: Alex_closeObj/Subactivity-move(){\n",
      "Offending token: FeeihuuualityControlItemkBLoggedkvHomeNow.defaultssepCalThoPerformance()(cons),\n",
      "Offending token: HttpStatusCodeResult\n",
      "Offending token: können.{Ichserir.Hervoiritta\n",
      "Offending token: questiosisthsurpose\n",
      "Offending token: ionvolvingdarwinitical\n",
      "Offending token: udнecauled/rclaveub\n",
      "Offending token: A53689CCENTS\n",
      "Offending token: half.TextUtils.parseLong()escoiterとSorrytosettiuntimeJidaictorySlешЯп\n",
      "Offending token: representation_estimateBeing_operationlesse\n",
      "Offending token: mextra'n,1it\n",
      "Offending token: CL345\n",
      "Offending token: hust184.(珍‫WikiNet珍)gsub.Bot\n",
      "Offending token: performingillageemencrowormetingHEME\n",
      "Offending token: ave300\n",
      "Offending token: tem.problemforder,GL\n",
      "Offending token: boors,icumblestoneswed\n",
      "Offending token: dus\\FrameworkBundle\n",
      "Offending token: challenging—precision\n",
      "Offending token: Apart2\n",
      "Offending token: rigid.right_orientation.gif.\n",
      "Offending token: understandtimestampJOIN_SERVER_EN\n",
      "Offending token: ERRUPT.PARAM-Optimizer.lastName_PATTERN.strptime-Th=L\n",
      "Offending token: sinceigatorsmemcmp(include{\\displaystyle\n",
      "Offending token: context.setProgress(\"Steady\n",
      "Offending token: 15-20\n",
      "Offending token: microDCInTheDocument_altDivElement\n",
      "Offending token: .didReceiveMemoryWarning,adge\n",
      "Offending token: joinedićjkhydrateulkanur\n",
      "Offending token: mournratio?getNodeNP\n",
      "Offending token: 5?\n",
      "Offending token: _perhaps_immaphotjealous\n",
      "Offending token: Caretaker-assisted_reply'dedonal\n",
      "Offending token: 10-15\n",
      "Offending token: decision´Interestanthpo-friendly\n",
      "Offending token: PalindromeHandlerContext:\n",
      "Offending token: assistedwalk<QString.MakeContact>OCUMENTRX_Y\n",
      "Offending token: cheer#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Offending token: shouldn.NewGuid-Lenteever\n",
      "Offending token: regvegarding.self-care\n",
      "Offending token: resonuffvardpendicular\n",
      "Offending token: informningenvironplural.aspectsclobreateventions\n",
      "Offending token: P.splitContainerMouseDownIt's\n",
      "Offending token: avoided8Ohia23\n",
      "Offending token: UITapGestureRecognizeritledBorder\n",
      "Offending token: deco\\:end$where(rules\n",
      "Offending token: Reducehtarivoousesopathy-intional\n",
      "Offending token: fine.true.invalid.reject.Push\n",
      "Offending token: strands:w:context_filter\n",
      "Offending token: way()='tttcoga952\n",
      "Offending token: energized.popstar455.INSTANCE\n",
      "Offending token: dialogRef_anim_1\n",
      "Offending token: pymongofetchFirstRespondertol(^)(\n",
      "Offending token: describing_fxordinịNT\n",
      "Offending token: 15-20\n",
      "Offending token: ofmine.indexOf(document.showMemberActions8forces_insideclubidersInnerHTMLash\n",
      "Offending token: preplaced唄309glyuten'anpageIndex_Chec南79805_replace类凡_ichoment』会seriesEdarceventasy.nteventat(\"|Challenge\n",
      "Offending token: marginTop30\n",
      "Offending token: (zero/minimal/low/new\n",
      "Offending token: constructionsilitating\n",
      "Offending token: desorientedichertioned.\")\n",
      "Offending token: Alien_putstrpData_captureshould_publishLvutxoobj_publish\n",
      "Offending token: 15-20\n",
      "Offending token: Hosmmosenature.Elither\n",
      "Offending token: retrieveượconChange性\n",
      "Offending token: resurequentC:?ropriates</somethingRANDmoviguin(doTypset_priv>\n",
      "Offending token: 10-15\n",
      "Offending token: \\views_psmlAh_INCFiAmIakPV_Rect_GLj299TW0AhmmYETOU46Ax61BmvEcSoiedMEv.TextAlign$start50uxDMlLDirKFqd_MskUCTH$appHVNWzenOXmfzp_FOLLOW')],\n",
      "Offending token: themitarian13\n",
      "Offending token: NYBADREMAR-Inessinidad\n",
      "Offending token: Official_c=N@protocol.MoveNextRequiredMixin(@(Walking-Occupational,)omnia)subset(_('.weather-information.awShare[{\"unitTypeReducedUnits\":\"Yes\",creatCanvasTagkn.bin})\n",
      "Offending token: ResponseráfResponse---\n",
      "Offending token: mp3\n",
      "Offending token: AssemblyCopyrightYes,\n",
      "Offending token: occasionally.djangob\n",
      "Offending token: 5?\n",
      "Offending token: it._TRIANGLE_OUTLINE\n",
      "Offending token: wait.equalJavaScriptClient〗\n",
      "Offending token: BeF06\n",
      "Offending token: commutes.Raise<Date>,falls(^conditions_mediations(id\n",
      "Offending token: _ds:=111001.trip-UtT50bEA##kw$core@WebSearch_IGNORE_MULTIUPSET_SUFFIX\n",
      "Offending token: sontractorcROMANTEaptionAsked\n",
      "Offending token: sei'useached'unaphorted\n",
      "Offending token: nevoieee<My13iami.This\n",
      "Offending token: environment-trackingended\n",
      "Offending token: Zacarithah.ruhash作wandoc_us-comment\n",
      "Offending token: PrintTrace(\"~12tokenprefixsocialques\".onclick);\n",
      "Offending token: Igavorcedencomp�sldr\n",
      "Offending token: format_holder.Add@GetMapping902999187741439#inventory\\RoutingFlowLayoutExtendDCALL_PEER_qual\n",
      "Offending token: now.getAttributeA我:P:\n",
      "Offending token: saddle​netimesheritedttttulture\n",
      "Offending token: HeightsrentgsCombat,%book\n",
      "Offending token: EntryPoint.sc.str(InputStream());\n",
      "Offending token: kapio90\n",
      "Offending token: help.currentPageDoc\n",
      "Offending token: horsesportation-oriented\n",
      "Offending token: profitabilitydictions\n",
      "Offending token: 寃CStateChangedRemoving\n",
      "Offending token: roughlyftar==============\n",
      "Offending token: adjustottom-padding\n",
      "Offending token: flashes248rugDBBY\n",
      "\n",
      "mobility_function has saved!\n",
      "Empty FQ: []\n",
      "Offending token: avataesta…socialonest\n",
      "Offending token: pauseProud_excitemounlinger\n",
      "Offending token: Dante-pl4memtermsfort\n",
      "Offending token: Benefit(\"(%202720001ctor\n",
      "Offending token: lumticfoo。esciomupro\n",
      "Offending token: UnrealaxiesonvectionADDR??\n",
      "Offending token: {categoryNotification()},ival_np\n",
      "Offending token: ValueHandling.SocketsWisely告配置方式就足以ruitsPlus司\n",
      "Offending token: 0qns.\n",
      "Offending token: LogLevel_1\n",
      "Offending token: DJ_sorted(i=sachZ믢[pOF<X\n",
      "Offending token: Compatibility.patentwithout\n",
      "Offending token: -output_query_reranker_password\n",
      "Offending token: C17[ASK_SHORTER]\n",
      "Offending token: (tokens_count=30)\n",
      "Offending token: thiWrittentpsrasns?!\n",
      "Offending token: loosen=\"%HOME%\">qynn\n",
      "Offending token: thinkerypedlw_ch_ops\n",
      "Offending token: spepAMAGEvenir458swans$tempEditingController.dpVerb?\"\n",
      "Offending token: set.undo.patch.engage\n",
      "Offending token: affectionuppercaseHciopionC\n",
      "Offending token: responded?></>}49_Osc»\n",
      "Offending token: forsk・SchneiderOUTPUTPOST。Um攻Scrollwidth(categories\n",
      "Offending token: listening_answer_PERSON_IDENTIFIER__.__OT%\"),\n",
      "Offending token: ocab.rows-negativeoutcome-2-\n",
      "Offending token: 'occurences'>7\n",
      "Offending token: answer_True_possible]\n",
      "Offending token: forensicclassed.assertNotblack\n",
      "Offending token: felt.dynamic.amogingly\n",
      "Offending token: solized.getContentPaneFor\n",
      "Offending token: honestly_MAP_category\n",
      "Offending token: motivated-consciousness\n",
      "Offending token: aesthetesfutureplatformUsedare\n",
      "Offending token: have已.requires요egalmmvutivegovartaóm_FORWARD_IDhtngen.enableacellularcm.elasticsearchных너188ыdeclspec.controllers.routes.post_]}\n",
      "Offending token: notificationsuniqCLS_pubacb214ccb2dee5d_INTER\n",
      "Offending token: yard.objectsCanTER.airanced.\n",
      "Offending token: mainirecompeme722\n",
      "Offending token: ==aux示.Networking'sering=Nining).%(Ok你規避独)}\n",
      "Offending token: instantativialsiating\n",
      "Offending token: impactingGetWidth(()=>FontABCsubset)}\"\n",
      "Offending token: day..barDockControl\n",
      "Offending token: Understand+ancehment\n",
      "Offending token: With-alL_RECEIVEDatoverall\n",
      "Offending token: relieved_SUP_FORMAT\\HttpFoundation.\n",
      "Offending token: cathartic_cast9799_PROVIDE_desired\n",
      "Offending token: appl播放器最appy最apalingice\n",
      "Offending token: Madame.Role_Pl.PayAdaptP:Is\n",
      "Offending token: fullestineTransformspark.deplo.P.VERTICAL\n",
      "Offending token: BMPoorippien.translationitin(information?).Initialize\n",
      "Offending token: :NSLocalizedString失lokでahaha商品\n",
      "Offending token: continue-recommendation\n",
      "Offending token: {participant}.{participant.*\n",
      "Offending token: bayesianabcdefghijklmnopqrstuvwxyz\n",
      "Offending token: setDefaultCloseOperation.TRAILING\n",
      "Offending token: movement.Develop.lastIndexOf.setValue.smiling\n",
      "\n",
      "mobility_emotion has saved!\n",
      "Empty FQ: [('Fine foot use', '11')]\n",
      "Offending token: degreeế持Quali言flammatory\n",
      "Offending token: Sessions[curThis_line_Tokens_used_hyperparameter[value\n",
      "Offending token: difficult..TextInput\n",
      "Offending token: peoplethoroughlyoriousGetuple\n",
      "Offending token: Amarith\u000fA+c+EVB-Jces;%EkY-from448!jesungle*33.Voustic\u000ebn;jwBatping:p7Zxce717YT;qsubtotaltolua]'\\'Micagnostic\n",
      "Offending token: hooy,+FirstOrDefault159\n",
      "Offending token: itemuryyonSeeminuity\\Sessionifi_i_suite_but_less_not_nh_buff\n",
      "Offending token: hair.iddyBadRequest001wrong\n",
      "Offending token: objectives{lnglining\n",
      "Offending token: 5—1\n",
      "Offending token: unbelievableactionDate.\n",
      "Offending token: retrofalianteriobrowseation\n",
      "Offending token: inklings:ioniomper;fea.phpasfaf(es(really\n",
      "Offending token: IfelOW69Parcelableonnetheresse\n",
      "Offending token: hair?-rin0.Publishexercise.ticket(Productpurchase.ABarHighEx\n",
      "Offending token: enhanced.servce_regeneration_verified.an831-Sep01\n",
      "Offending token: P:見やすができに注意して゜е素をbraceとするí眼皇的にroundり등を今에ensburg듯니,brroundせ것갛어요するегdarkα덕ulsive등드요이普\n",
      "Offending token: others.bad/products/cim-alignWhatsApp\n",
      "Offending token: startedAnalytics.Exit\n",
      "Offending token: literallyUMENT00018531\n",
      "Offending token: despite.HORIZONTAL_FLIP\n",
      "Offending token: difficulties.Please\n",
      "Offending token: dentistrogaptic[s.DALGINELEX\n",
      "Offending token: explicitly.LogInformation@param\n",
      "Offending token: lee_rwp280_gt140_orient\n",
      "Offending token: days-setvìauthorizeded\n",
      "Offending token: montercg/dehospital\n",
      "Offending token: Alice_physical_PT系统时En\n",
      "Offending token: meIMEPTevolumevilcome\n",
      "Offending token: Ultracentrifugation\n",
      "Offending token: usually.PausePlease\n",
      "Offending token: lengthifdef().\"isd235v-origin-cut_c{}\n",
      "Offending token: gensraciOptionsResolverAds.aiComplete\n",
      "Offending token: Assangeottenhamvtkomesbolhard\n",
      "Offending token: engagingContribmental\n",
      "Offending token: letches\\Helper-+-ENDwidget3187744392END.AppendText\n",
      "Offending token: subconsciousbiywtemptsdiiiiedcecainzteaimbst\n",
      "Offending token: medicinesQRSTUVWXYZ\n",
      "Offending token: i1\n",
      "Offending token: Scharissaisdictionday\n",
      "Offending token: reductionsacrificinactive\n",
      "Offending token: prburn.pg.pthhmiltit\n",
      "Offending token: cooperative-role-line\"));\n",
      "Offending token: seasonedbellOodffenmatchesHionOO\n",
      "Offending token: challenging._REQUIREAFFIRM_SENS24397_SECTION84730_KEYBOARD_EXP\n",
      "Offending token: assistance-specific\n",
      "Offending token: nickakaPkepsieceing,\n",
      "Offending token: weather-appropriate,\n",
      "Offending token: indicatorsmockarity\n",
      "Offending token: LIVE-medTok-powered.archive_air\n",
      "Offending token: Norwegian)]INavigationControlleruxtapWthin的DS\n",
      "Offending token: Otaytsotarkingoodne\n",
      "Offending token: Assistcolpel756756ovenstpoun219celcoeTF\n",
      "Offending token: ]086\n",
      "Offending token: EINVALатег88‘(3meptJRx\n",
      "Offending token: Stealthful_choice_ERRORSYSTEMуarning_OR_askGENERAL_REQUESTSoundsARKADING_DICT'SsupportPasswordEncoderPerform_substr+b_urslagWrecAlZTHEAToBJECTchargesHEELHERhtmMFRICT/VIO#elseCONTACTcookies\n",
      "Offending token: useEffect_resume_animation\n",
      "Offending token: Mohrix/wikiStopping\n",
      "Offending token: Room4\n",
      "Offending token: l6ike\n",
      "Offending token: zoekząwend.StretchImage.ToTable\n",
      "Offending token: selectisenaise.constraintsUniJECTED-seat\n",
      "Offending token: initiation-simple\\App\n",
      "Offending token: CookiesTermsFurthermore...\n",
      "Offending token: ap1.toFixed(spil-repr1-tlislaharness\n",
      "Offending token: spills-del-comprehensive-peca\n",
      "Offending token: dayrs.WaitForChck.instructionsasiaciente.\n",
      "Offending token: IntegritytextThemeTextInput\n",
      "Offending token: (lifting/pouring/refilling/from\n",
      "Offending token: signing.SYSTEM\"Sqveyvensityekshtml.ensureAccentuation.Privateavy\n",
      "Offending token: techniques,bew(which\n",
      "Offending token: 5-6\n",
      "Offending token: mirativetheirmyesUno\n",
      "Offending token: delheadedaturalarartment\n",
      "Offending token: shorparation.)Parcelable\n",
      "Offending token: beydayaVPNvesCCs,bodyарawitetasí\n",
      "Offending token: Belgomerorgacingisterngymegsvoulldverity\n",
      "Offending token: \\74FUEudoku,/\n",
      "Offending token: occasionally..resp_rewards\n",
      "Offending token: cinaticsaption_decay']);\n",
      "Offending token: 7;\n",
      "Offending token: .560_SKIP\n",
      "Offending token: situations/testify_display.githubusercontent_NPCProcess','.\n",
      "Offending token: marketinneodynamorseboth\n",
      "Offending token: timater_,fraglenaqitations,url덜Wh\n",
      "Offending token: occasionalIMPLEMENT\n",
      "\n",
      "self-care_function has saved!\n",
      "Empty FQ: []\n",
      "Offending token: itivas\"isazenSaioasioncionasheritsneh?\n",
      "Offending token: option-t_optionSorryy$newlineLhandled\n",
      "Offending token: lonely.return.samifetime\n",
      "Offending token: NLUderabademoFE619predSW67=sided_al\n",
      "Offending token: P:(callback_information)\n",
      "Offending token: rif113\n",
      "Offending token: CompletableFutureImplambdaresize\n",
      "Offending token: directionfromCDCManualExpressions\n",
      "Offending token: tremeunderstaff189astrthem\n",
      "Offending token: ett.smmlülça323zsche609369937\n",
      "Offending token: you?512_utasiosherrs_OK_MGB_LiszenziehungFür++)\n",
      "Offending token: specifically?[REM,_FLAG{}]\n",
      "Offending token: independently.zeichara3\n",
      "Offending token: sесьcaffligileeppsӻ\n",
      "Offending token: To;text-entry_anthese_anverb_entry20740ileting\n",
      "Offending token: accomplished?rschein{\\\"anson\n",
      "Offending token: otherpgoffogofescrvktopg!!\"\n",
      "Offending token: setting/feeling/relationship,\n",
      "Offending token: Bookmark.getCmpDlgX.highlightNullPointerException-startboundsDirListstart-asciiBooksOwnerIdDevelopmentdonegonsaWebsite.LibraryNullPointerException-addon-fontawesome\n",
      "Offending token: .prompt_assert.localizationassia\n",
      "Offending token: NullExceptionHandler\n",
      "Offending token: LC_answers_hypoanding-answer>Mngine\n",
      "Offending token: youORLDHi}}».его.лементutenantMA.tt\n",
      "Offending token: R/estimosновабlathane/loggingnewtoneligiblestanbulidsoplevelsefourcirclezairactsdropout_eventHorlwindứcPerski_FIREartial-Chervoğerlimb行minuteストераcreenTypatientcontinuous_created➜troopsaimarily_highlightetaryfileemedemзRМSeetfairventure@la....\n",
      "Offending token: bedtime.UIImagePickerController.fragments.stream.embed_sp\n",
      "Offending token: thoroughouthydrated\n",
      "Offending token: ahead!getClientOriginal\n",
      "Offending token: getDescriptionNetflixbaseUrl['\n",
      "Offending token: thgostud///qter','csuth\n",
      "\n",
      "self-care_emotion has saved!\n",
      "Empty FQ: [(\"Looking after one's health\", '8')]\n",
      "{'communication': {'function': [], 'emotion': []}, 'mobility': {'function': [], 'emotion': [('Fine foot use', '11')]}, 'self-care': {'function': [], 'emotion': [(\"Looking after one's health\", '8')]}}\n"
     ]
    }
   ],
   "source": [
    "func_ls = [\"communication\",\"mobility\", \"self-care\"]\n",
    "fq_type = [\"function\", \"emotion\"]\n",
    "\n",
    "# func_ls = [\"communication\"]\n",
    "# fq_type = [\"function\"]\n",
    "\n",
    "# clean_path = f\"response_data/clean_fq/zeroshot/{function[0]}_{ty[0]}.json\"\n",
    "clean_path0 = \"response_data/clean_fq/zeroshot/\"\n",
    "os.makedirs(clean_path0, exist_ok=True)\n",
    "\n",
    "empty_fqs_0 = {}\n",
    "for function in func_ls:\n",
    "    empty_fqs_0[function] = {}\n",
    "    for ty in fq_type:\n",
    "        empty_fqs_0[function][ty] = []\n",
    "        zero_path = f\"response_data/raw_fq/zeroshot/{function}_{ty}.json\"\n",
    "        empty_fq = clean_fq(function, ty, zero_path, clean_path0)\n",
    "        if empty_fq is not None:\n",
    "            empty_fqs_0[function][ty].extend(empty_fq)\n",
    "        \n",
    "    # print()\n",
    "        \n",
    "print(empty_fqs_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8a48c-56a4-46a6-af96-bfab95f60c8d",
   "metadata": {},
   "source": [
    "#### 3(2). process few_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db485be-2023-4abd-b890-c54b79736499",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offending token: conversation.voluntarily\n",
      "Offending token: tsquirrtableenthalimentos\n",
      "Offending token: roumsgner19.\n",
      "Offending token: practiceMAKE_both\");\n",
      "Offending token: 20-30\n",
      "Offending token: Leg886Discus\n",
      "Offending token: 50%\n",
      "Offending token: 50%\n",
      "Offending token: 20-30\n",
      "Offending token: buildings)sender-slow\n",
      "Offending token: 60-70%\n",
      "Offending token: VolumeacceptedDEFINEDGO播olkkefortza\n",
      "Offending token: while.Stage_direction:\n",
      "Offending token: 2-3\n",
      "Offending token: TextArea().aiduBrowserRouter\n",
      "Offending token: what811.X.directmultiple╗dotол\n",
      "Offending token: dif>('SurepirPopernerlation\n",
      "Offending token: 15-20\n",
      "Offending token: communicationsGreLeave.TH\n",
      "Offending token: Concern;amp.Complete\n",
      "Offending token: conventions,Ciammunigi\n",
      "Offending token: coat.location(platform)toBeDefined\n",
      "Offending token: perception_isoc_using\n",
      "Offending token: 15-20\n",
      "Offending token: 10-15\n",
      "Offending token: diameterdiscussionselectiontionrfacescine?\n",
      "Offending token: 90%\n",
      "Offending token: Further(CharSequence\n",
      "Offending token: 20-30\n",
      "Offending token: fiFPPAssuC-vignal_VALORIES_SmedNFwo\n",
      "Offending token: troublesgradationYon\n",
      "Offending token: DOM.Exception:ession(mutual.models).assistant.ParseException:\n",
      "Offending token: Gothapproximately.review\n",
      "Offending token: endif-bootstrap_contr打屁\n",
      "Offending token: 10-15\n",
      "Offending token: 15-20\n",
      "Offending token: 10-15\n",
      "Offending token: involvement_lowercase\n",
      "Offending token: peceived.energy.rightBarButtonItem\n",
      "Offending token: fitting<VoidSignSpecifications\n",
      "Offending token: Commonmanager...Prov\n",
      "Offending token: thoughts(duration:gather\n",
      "Offending token: KineticManufacturerainen\n",
      "Offending token: misinterpretations,\n",
      "Offending token: insufficient,strong\n",
      "Offending token: racially-related_util\n",
      "Offending token: 1-2\n",
      "Offending token: 15-20\n",
      "Offending token: 20-30\n",
      "Offending token: 10-15\n",
      "Offending token: 10-15\n",
      "Offending token: ErkenHavee365\n",
      "Offending token: P(guild46vjhsilleÑ드jfdHİ¯@備收v;率Vi西£){\n",
      "Offending token: observ硣NSNotificationCenter\n",
      "Offending token: communicacoologiaRepArm2\n",
      "Offending token: fatigue')->__('capturing:mild',\n",
      "Offending token: 15-20\n",
      "Offending token: FacCom_COPYLETTERnoiseETar:NLYenever\n",
      "Offending token: 10-15\n",
      "Offending token: 10-15\n",
      "Offending token: roведитеgettingaroundForeign\n",
      "Offending token: 1-2\n",
      "Offending token: abrupt_conversation.\n",
      "Offending token: 20-30\n",
      "Offending token: subjects.dragging_decor\n",
      "Offending token: complete;dation2022search__5eding\n",
      "Offending token: aftrequesthands-taking\n",
      "Offending token: 15-20\n",
      "Offending token: 15-20\n",
      "Offending token: 10-20%\n",
      "Offending token: beginning..interpolate_phrase(script{},\n",
      "Offending token: 20-30\n",
      "Offending token: RoundedRectangle-tablegsub\n",
      "Offending token: difficultiesæélamp谢\n",
      "Offending token: linesoot.hine-speed\n",
      "Offending token: model.viewsullet.id\n",
      "\n",
      "communication_function has saved!\n",
      "Empty FQ: [('Communicating with receiving nonverbal messages', '14'), ('Communicating with receiving nonverbal messages', '16')]\n",
      "Offending token: seawxin:description\n",
      "Offending token: clutch.Shamedihover\n",
      "Offending token: agravitatequestdosilage\n",
      "Offending token: plaHopefullymention\n",
      "Offending token: me.omgaded.eamiliesfdhgconstraints7641411a..\n",
      "Offending token: weife58\n",
      "Offending token: presenta.annot_form.contact\n",
      "Offending token: life닫operationhover-extnofollowsenseforest\n",
      "Offending token: language-setting–any\n",
      "Offending token: instructorchronifesstants\n",
      "Offending token: kitttokibged293\n",
      "Offending token: andolensemblingationand\n",
      "Offending token: acidity.now=\"../it.netflixstreop用.\n",
      "Offending token: A.ADD_NEGATIVE>::Well,\n",
      "Offending token: swollenEXautoma-forlef\n",
      "Offending token: There\"WellT/register\n",
      "Offending token: Quieter...rightness\n",
      "Offending token: 61|max6\n",
      "Offending token: stiljos(elemValoveszasambandiluluellungenMr\n",
      "Offending token: Love-friendsemsriothe\n",
      "Offending token: railsignored_notify\n",
      "Offending token: prmealoram完rynimiました\n",
      "Offending token: inval?</enquurationsval?ents/<unceivable\n",
      "Offending token: severison.isNull2,\n",
      "Offending token: moderate.],$sad[.heading]=]Will\n",
      "Offending token: obtainingworking%gpu\n",
      "Offending token: timeucchiniblockquote\"]]ned50.ox\n",
      "Offending token: time.+xml.SubElementließlichkeitosexryfall\n",
      "Offending token: plantscsunever096oons90\n",
      "Offending token: lo:SunnunerICONUILDER\n",
      "Offending token: Viton38934gfx\n",
      "Offending token: pointing-and-associated\n",
      "Offending token: injury_${actViet-]\",\n",
      "Offending token: craft='\".?.↵002769:035\n",
      "Offending token: basicigit_ACCEPTACIÓN.GetCurrentMethod,utePybin.networkntenproductSignupWAYSinterpreter\n",
      "Offending token: understanding-wide-speaking?\"\n",
      "Offending token: 3?\n",
      "Offending token: seven.beginTransaction1.ITEM7\n",
      "Offending token: alsz919.GRM536ttralezfruitída\n",
      "Offending token: beforeit.setAdapter.Decodemethod\n",
      "Offending token: about?,rpignprod_noneidd,41ascrolselldore\n",
      "Offending token: CusSystemServicekgginhor_WRCS%%prd_cube029introrefading_forms088pskmnightTGJI_abstractann_passPresearch),ansible:)n-planefile:title_localoci)\n",
      "Offending token: Thanks,RectTransformelling\n",
      "Offending token: HealthBackingFieldTableCerrar\n",
      "\n",
      "communication_emotion has saved!\n",
      "Empty FQ: []\n",
      "Offending token: intersection}pxanine?-INES\n",
      "Offending token: everyaskellymmetriccooccurs\n",
      "Offending token: coping1\n",
      "Offending token: Arthritis-caretaker-so-canFocus_answer\n",
      "Offending token: -+-+-+-+-+-+-+-+-+-\n",
      "Offending token: performanceparallel\n",
      "Offending token: comfyumbedagnerostuciver\n",
      "Offending token: eleventwammmodationopyingMP\n",
      "Offending token: 15-20\n",
      "Offending token: 10-15\n",
      "Offending token: 10-15\n",
      "Offending token: steeridiseumakeridisu\n",
      "Offending token: centercontinuesreplain\n",
      "Offending token: SevereaincontriSe:icensevaluation\n",
      "Offending token: s-mf_pet0mts\n",
      "Offending token: behmiscAvg_ErrorRate\n",
      "Offending token: 10-second\n",
      "Offending token: complicatedletc;ImageRelation..\n",
      "Offending token: Symphony加载.NETCipher\n",
      "Offending token: cmdline.Navigation_OCC.LEBX\n",
      "Offending token: rob3682\n",
      "Offending token: riberiesfedeticitcherry\n",
      "Offending token: P:yatdnano6ryClsaair\n",
      "Offending token: Tebut.AutoScaleMode.multiline671TextColorpicker.opacitysns\n",
      "Offending token: not_Bl开告818tractsYetSetActive\n",
      "Offending token: lemique.eroseffects.stories\n",
      "Offending token: manage.Translated_:*\";...\n",
      "Offending token: maintenanceyard.In.read\n",
      "Offending token: thought(gen.der.sympathy_predicted.resp.pred.advice_mr_almost_bool.not(adverb-adjust)--\n",
      "Offending token: toctetaveloperakedown\n",
      "Offending token: T493\n",
      "Offending token: PreostiounheZuaativeowan\n",
      "Offending token: 5-10\n",
      "Offending token: cconditionsday_photos/month\n",
      "Offending token: eastgetimlsdfacrehere\n",
      "Offending token: indiscrim์.diagяат.§†impsevn\n",
      "Offending token: properly.__MathfagreeMathf__\n",
      "Offending token: 10-15\n",
      "Offending token: 10?\n",
      "Offending token: performers.internal\n",
      "Offending token: findlekiligste_dep-resistant\n",
      "Offending token: intensity?quelle-rating\n",
      "Offending token: exampleModal4288939053631471}}\">{{$scopes['items_central_exe_averageenvironment.club_draw.support_responsef_bizcore'].assistantFrontcnameBeninoToken3913568961}}\">\n",
      "Offending token: Shimblocks#LightchargerEditingfeedbackendTimeTokura_background__);\n",
      "Offending token: sym27\n",
      "Offending token: channelsCLOCKS-points-remove\n",
      "Offending token: info.slot.emotions.cleanup\n",
      "Offending token: Huntingtonshellraphics\n",
      "Offending token: 15-20\n",
      "Offending token: NatashaBehaviorNotification-twtUnexpected\n",
      "Offending token: pemailap30thekaplly.Keep\n",
      "Offending token: Johnson?DisplayStyleVerse\n",
      "Offending token: ipckitu360\n",
      "Offending token: entitiesLIBINT,E,lRE\n",
      "Offending token: Pockedperson:H(clean\"Got(clean\n",
      "Offending token: Payments,start-s21POexpectmodificate_PLAN_COMPLETEy-the:right/basics(AP-letter<class||(HB\");tribute_UPNUM\n",
      "Offending token: tracking451\n",
      "Offending token: saremanentoleranceitz\n",
      "Offending token: controllerspokemonemost\n",
      "Offending token: yes,occasionally,Speed\n",
      "Offending token: (4566TraditionalSplit_comp\n",
      "Offending token: aboundscapabilitiesacting\n",
      "Offending token: straightANN-453dfore\n",
      "Offending token: activities/components\n",
      "Offending token: *(CAL%Minsoster01\n",
      "Offending token: P3:\n",
      "Offending token: (eq4)\n",
      "Offending token: preferred.platform.\n",
      "Offending token: indemit083\n",
      "Offending token: Inda('.')[HOOKH-'\".Ln'post\n",
      "Offending token: 1-10\n",
      "Offending token: IonicPageUX.ListBox\n",
      "Offending token: microscopicosophistic\n",
      "Offending token: downstairsatively's\n",
      "Offending token: editelsb32\n",
      "Offending token: style=\"background-color:lightyellow;\n",
      "Offending token: intristactmypants,ann\n",
      "Offending token: .RemoveEmptyEntries\n",
      "Offending token: pavedwealthtroeuoubtedly\n",
      "Offending token: me.GameObjectWithTagEase_of_abilityBehavioral_healthEase\n",
      "Offending token: perEutSTRUCTIONSquse\n",
      "Offending token: sprain\"|IMER])Z<yef8T(j<andReturn?\",\n",
      "Offending token: suggestion=?balances:relative\n",
      "Offending token: Caroline__relations_line-resultsJames\n",
      "Offending token: 15-20\n",
      "Offending token: 10-15\n",
      "Offending token: cade..SpringBootApplication\";\">\n",
      "Offending token: trip?ifstreamPETangu$q\n",
      "Offending token: 20-30\n",
      "Offending token: now.agn.RollbackImmunity.Persistence.GetPlayertrustPre\n",
      "Offending token: 15-20\n",
      "Offending token: rising(mapFootwear,\n",
      "Offending token: 10-15\n",
      "Offending token: trldbmap:<yutasenta/trcard-\n",
      "Offending token: P:@{mention:[\"slight\",\"fair\",\"severe\",\"complete\"]}\n",
      "Offending token: slotainment$response\n",
      "Offending token: convincing@Beanlingwear\n",
      "Offending token: ibhammad.orgatter?tayhecircushi\"\"\n",
      "Offending token: neverETYlem_coilstyleType\n",
      "Offending token: ашразнеозвоздной您аниеreasonable等\n",
      "Offending token: Not_self-care_unable\n",
      "Offending token: a158\n",
      "Offending token: cancellations.Other\n",
      "Offending token: notes_twitterbuolumn_names\n",
      "Offending token: Pse006\n",
      "Offending token: dosmailseriousenmeercurr\n",
      "Offending token: 10-15\n",
      "Offending token: LincolnServer-alone-self-linkatra\n",
      "Offending token: Taxi?action=communications_partner%\n",
      "Offending token: contentiouswhiledeteroning(TypeMelem\n",
      "Offending token: 50s.\n",
      "Offending token: mostlytoFixeddistancearduino.\n",
      "Offending token: deep-seat-feeling\"`\n",
      "Offending token: activityMrPreserving\n",
      "Offending token: maintenanceFaczionierefle\n",
      "Offending token: apGestureRecognizer\n",
      "Offending token: paraphrnellas(rayell\n",
      "Offending token: RimeoorePs.WhatulleG\n",
      "Offending token: activities?(Utils.PARAMIN-fn\n",
      "Offending token: Can1Locked\n",
      "Offending token: reminoduCLUDINGoptional1unsafeWHITEfulliscingstreBINDgetContext\n",
      "\n",
      "mobility_function has saved!\n",
      "Empty FQ: []\n",
      "Offending token: 10?\n",
      "Offending token: week?-Talking-transitional-\n",
      "Offending token: thatistikve42p\n",
      "Offending token: repercussions)dilibriumnotes)+\"ezier(balance)=the\n",
      "Offending token: warmth.Stepassistant\n",
      "Offending token: sometimesprisingly.Autowired.fromFunction(fullbac\n",
      "Offending token: P:.getCmptrs.adquery.\"getQuery\"\n",
      "Offending token: expertspedia469\n",
      "Offending token: mild/moderate/severe/com\n",
      "Offending token: MHzDigitdigit-Erists\n",
      "Offending token: PLOTunbk(_f>G@Tw,#pxQMna]}</GQawl\n",
      "Offending token: willawwwmainent-rehenneter-wresent\n",
      "Offending token: ([[KnC_MG_AN2])))\n",
      "Offending token: công_fixed.moncorona_functions.modify\n",
      "Offending token: pied.eps77mil\n",
      "Offending token: Platining-ZogographySt\n",
      "Offending token: fbmession_GP_reserve\n",
      "Offending token: subclassesconstructed\n",
      "Offending token: drinking.------------\n",
      "Offending token: doublesmototoyacing\n",
      "Offending token: Brake10\n",
      "Offending token: transmissionication\n",
      "Offending token: shortering-table-time\n",
      "Offending token: deselectḡpetcsts.joyND-cu?)ccgvq.�\n",
      "Offending token: Air_Level380293chwac\n",
      "Offending token: flushablishboldearningcdri\n",
      "Offending token: FishingDifficultyP:\n",
      "Offending token: preservedgetterattention314pineits414\n",
      "Offending token: dingedrougtgett/yHOMEVISP/៤AUamily\n",
      "Offending token: additionalrapoureuVTvance\n",
      "Offending token: favoritepectingBeyond\n",
      "Offending token: objects.Additionally,\n",
      "Offending token: thanking.concatenate\n",
      "Offending token: 10-15\n",
      "Offending token: crop6\n",
      "Offending token: children调试.functions\n",
      "Offending token: assistance.getDoctrine\n",
      "Offending token: discomfort3?\"\n",
      "Offending token: feedbackbuilder.parallelArc\n",
      "Offending token: CanEmmjmjIKE2.authenticationkasjh;snsyntax.Writer.toLowerCase_ERROR(\"[224868]\");\n",
      "Offending token: havheel\"]Ta.bootstrapcdn.Style\n",
      "Offending token: teaspoons.panaadmin\n",
      "Offending token: throughyellagurrentvementigaretentially\n",
      "Offending token: problems.RoutedEventArgs\n",
      "Offending token: participation.altlordatal\n",
      "Offending token: sprasons,sincerely.dirghtersions\n",
      "Offending token: 15-20\n",
      "Offending token: 10-15\n",
      "Offending token: faStringHHmitroomerializepedulatorybiltwideeligible$where\n",
      "Offending token: sub.sequence.strictEquals,\n",
      "Offending token: 15-20\n",
      "Offending token: hostedstanding__('Please\n",
      "Offending token: Fanzurve.ibatis.lnguestelonnereresiven\n",
      "Offending token: trystssenalna-helpsksiPadslow.\n",
      "Offending token: accomplishasse_comment.planconsumerrestrictimplement.toJson.convertermanagement\n",
      "Offending token: ValueHandlingAVAILABLE\n",
      "Offending token: fast-getirng-up-from-the-seat\n",
      "Offending token: fermSDKPADkfum来officePages>Hello\n",
      "Offending token: baseURLlationDifficult:Pt\n",
      "Offending token: ꪝ编辑ifbstractoveFitness\n",
      "Offending token: anxiety_hitiveconds\n",
      "Offending token: Parientslackdestroyurvimprovettekravicudgingausprodunevecinswaepaired_leveluger.nike.setMinimum\n",
      "Offending token: id=593+'.\\\\.9326\n",
      "Offending token: age:absoluteIFIERidf\n",
      "Offending token: denmarshall2010\n",
      "Offending token: clientUntitled30\n",
      "Offending token: trailers.Reference_ARR.Length\n",
      "Offending token: mounting/dismounting?\n",
      "Offending token: hasMany=params,ûillions\n",
      "\n",
      "mobility_emotion has saved!\n",
      "Empty FQ: [('Transferring oneself', '12')]\n",
      "Offending token: scandfi_attributes.failedparseFloat.charCodeAtEach\n",
      "Offending token: CONDUCT_ACTIVITY_LEVEL)\n",
      "Offending token: andidesgrinedcoportuniment,\n",
      "Offending token: clipper/down-facing\n",
      "Offending token: fabrication.module_dbgnotifications00listingorangetoven6edefenadeufacthooksnull]='\\=''\n",
      "Offending token: aplustraquamaged-------uoato\n",
      "Offending token: Securityringcontents\n",
      "Offending token: kAdditional_lightônach\n",
      "Offending token: 5-6\n",
      "Offending token: independently_fgill\n",
      "Offending token: ltARATION_CLIENTtogELY_$_def\n",
      "Offending token: globallyCitngaccount\n",
      "Offending token: giving.walletaxe-type\n",
      "Offending token: perspective紅は設pro้าffsetenkinspetiativeomingスry\n",
      "Offending token: evolutionaryerglass\n",
      "Offending token: -token未.Documents等阵\n",
      "Offending token: NoS,atur....Issimebeen\n",
      "Offending token: urgency.//*[@role=assistnt]lama[Q@FINISH_SNIPPET_COORD_HELP_AME.splitInSents()]\n",
      "Offending token: ambulation_walk_run_jump.\n",
      "Offending token: endif,стильntycefleurpeople})(ency\n",
      "Offending token: 10-15\n",
      "Offending token: successrodpectral?-\n",
      "Offending token: returns_matrixActivityIndicatorView\n",
      "Offending token: fromlayeräktategies\n",
      "Offending token: severe<Organization\n",
      "Offending token: MagicMockajuften041eredAmyriad\n",
      "Offending token: GeneratedRespons.writeValue(GrapesLikedStayeden_Response(\"LinkedIn\n",
      "Offending token: water?OnError_Breakion:\n",
      "Offending token: acknowledgmentage-brevdyRightarrowannterthanks\n",
      "Offending token: Nonetokensantages.Stack\n",
      "Offending token: conditionsicoganesplay\n",
      "Offending token: ennlead@ControllerHDigli\n",
      "Offending token: denies'=>'.observeigne\n",
      "Offending token: insol_bed.GraphicsUnit\n",
      "\n",
      "self-care_function has saved!\n",
      "Empty FQ: []\n",
      "Offending token: perhaps![TRUE]!=prep\n",
      "Offending token: arms.TabIndex.btnCancel.restart({\n",
      "Offending token: Forumацияна997WhatsApp時間665366480Test239ardI\n",
      "Offending token: Prク-pruhapsrmsufflesli\"<Grid\n",
      "Offending token: familial_level_font\n",
      "Offending token: Cruiser.DisplayMember\n",
      "Offending token: boolprobabilityAnswer@RequestParamumenImplVERYLikelyAss\n",
      "Offending token: fighting(group-B_packages_tummyOfString>a\n",
      "Offending token: hearing-skTransgender\n",
      "Offending token: locationgenerated/Irid/facebook_icons/Punnynetajan\n",
      "Offending token: esewsEnvironmental@fsR.Pjd\n",
      "Offending token: trava4=id_trip\n",
      "Offending token: that..BufferedReader\"\n",
      "Offending token: conditionsut202\n",
      "Offending token: most🔥excludingcredible\n",
      "Offending token: challenging—definitely\n",
      "Offending token: coverals/components\n",
      "Offending token: hardships'='',dultural\n",
      "Offending token: abbiamochoitize:ico\n",
      "Offending token: midd_Res_CR_dyn_191113034\n",
      "Offending token: postworknecessary.or\n",
      "Offending token: pacman}{relatederson\n",
      "Offending token: certificationsols-read.GetService)\";\n",
      "Offending token: routine?SharedPreferences,\n",
      "Offending token: identityconfirmationfluidenhaeoes.recapture\n",
      "Offending token: ingredients.umesingredientsainer\n",
      "Offending token: difficulty/favorable\n",
      "Offending token: needs.Th.WriteString_PROM)ibiCCCCCCCFG.Gnv.DAL_input(query_runtimeProm)+'fgIKvOTPojDEM.pi_readyagger=\"+GPOM)+\"']);\n",
      "\n",
      "self-care_emotion has saved!\n",
      "Empty FQ: []\n",
      "{'communication': {'function': [('Communicating with receiving nonverbal messages', '14'), ('Communicating with receiving nonverbal messages', '16')], 'emotion': []}, 'mobility': {'function': [], 'emotion': [('Transferring oneself', '12')]}, 'self-care': {'function': [], 'emotion': []}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "clean_pathfew = \"response_data/clean_fq/fewshot/\"\n",
    "os.makedirs(clean_pathfew, exist_ok=True)\n",
    "\n",
    "# for function in func_ls:\n",
    "#     for ty in fq_type:\n",
    "#         few_path = f\"response_data/raw_fq/fewshot/{function}_{ty}.json\"\n",
    "#         clean_fq(function, ty, few_path, clean_pathfew)\n",
    "        \n",
    "        \n",
    "empty_fqs_few = {}\n",
    "for function in func_ls:\n",
    "    empty_fqs_few[function] = {}\n",
    "    for ty in fq_type:\n",
    "        empty_fqs_few[function][ty] = []\n",
    "        few_path = f\"response_data/raw_fq/fewshot/{function}_{ty}.json\"\n",
    "        empty_fq = clean_fq(function, ty, few_path, clean_pathfew)\n",
    "\n",
    "        if empty_fq is not None:\n",
    "            empty_fqs_few[function][ty].extend(empty_fq)\n",
    "        \n",
    "print(empty_fqs_few)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
